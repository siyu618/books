# 深度学习：推荐系统

## Chapter 1：互联网的增长引擎 - 推荐系统
### 1.1 为什么是增长引擎
1. 用户角度：推荐系统解决在“信息过载”的情况下，用户如何高效的获取感兴趣的信息的问题。
2. 公司角度：推荐系统解决产品能够最大限度的吸引用户、留存用户、增加用户粘性、提高用户转化率的问题，从而达到公司商业目标连续增长的目的。
   * CVR： conversion rate，用户转化率
   
### 1.2 推荐系统架构   
1. 逻辑架构
   * F(user, item, context)
2. 技术架构
   * 数据部分
      * 用户信息、物品信息、场景信息
      * 特征工程
      * 用户特征、物品特征、场景特征
   * 模型部分   
      * 召回、粗排、精排、策略（再排序）
      * 模型离线训练（离线评估）、模型在线训练
      * AB 测试

## Chapter 2：前深度学习时代 - 推荐系统的进化之道
### 2.1 传统推荐模型的演化关系图
* 协同过滤算法族：UserCF、ItemCF、MF
* 逻辑回归模型族：LR、LS-PLM
* 因子分解机模型族：FM、FFM
* 组合模型：GBDT + LR      


### 2.2 协同过滤
* UserCF 适用于发现热点，以及跟踪热点的趋势
* ItemCF 更适用于兴趣变化较为稳定的应用

### 2.3 矩阵分解算法 - 协同过滤的进化
* 在矩阵分解的算法框架下：用户和物品的隐向量是通过分解协同过滤生成的共现矩阵得到的。
* 矩阵分解的求解过程：
   * 特征值分解：只适用于方阵
   * 奇异值分解
   * 梯度下降
* 矩阵分解的优缺点
   * 优点：泛化能力强；空间复杂度低；更好的扩展性和灵活性。
   * 缺点：不便加入用户、物品和上下文的特征，这使得矩阵分解丧失了利用很多有效信息的结汇；同时在缺乏用户历史行为时，无法进行有效的推荐。

### 2.4 逻辑回归 - 融合做种特征值的推荐模型
* 逻辑回归将推荐问题转化为一个点击率预估的问题。 
* 基于逻辑回归的推荐过程：
   * 将用户年龄、性别、物品属性、当前时间、当前地点等特征转化成数值型特征向量
   * 确定逻辑回归模型的优化目标（以优化 CTR 为例）   ，利用已有的样本数据对逻辑回归模型进行训练，确定逻辑回归模型的内部参数。
   * 在模型服务阶段，特征向量输入逻辑回归模型，经过逻辑回归模型的推断，得到用户点击物品的概率。
   * 利用点击概率对所有候选物进行排序，得到推荐列表。
* 利用 sigmoid 函数
* 逻辑回归训练方法
   * 梯度下降法
   * 牛对法
   * 拟牛顿法
* 逻辑回归的优缺点 
   * 优点：数学含以上的支撑；可解释性强；工程化的需要。
   * 缺点：表达能力不强，无法进行特征的交叉、特征筛选等一系列较为高级的操作。

### 2.5 从 FM 到 FFM - 自动特征交叉的解决方案
* POLY2 模型
* FM 模型 - 隐向量特征交叉
* FFM 模型 - 引入特征于的概念
   * 为模型引入了跟过有价值的信息，使模型表达能力更强。

### 2.6 GBDT + LR - 特征工程模型化的开端
* GBDT 构建特征工程和 利用 LR 预估 CTR 这两步是独立训练的。
* GBDT
   * 容易产生过拟合，以及 GBDT 的特征转换方式实际上丢失了大量特征的数值信息，因此不能简单地说 GBDT 特征交叉能力强，效果就比 FFM 好，在模型的选择和调优上，永远都是多种因素综合作用的结果。

### 2.7 LS-PLM 阿里巴巴曾经的主流推荐模型
* 也叫 MLR（Mixed Logistic Regression，混合逻辑回归）
* LS-PLM 优缺点
   * 有点：端到端的非线性学习能力；模型稀疏性强。   

### 2.8 总结

|模型名称|基本原则|特点|局限性|
|---|---|---|---|
|协同过滤|根据用户的行为历史生成 用户-物品 共现矩阵，利用用户相似性和物品相似性进行推荐|原理简单、直接，应用广泛|泛化能力差，处理稀疏矩阵的能力差，推荐结果的头部效应明显|
|矩阵分解|将协同过滤的共现矩阵分解为用户矩阵和物品矩阵，利用用户隐向量和物品隐向量的内积进行排序并推荐|相较协同过滤，泛化能力有所增强，对稀疏矩阵的处理能力有所增强|除了用户历史行为数据，难以利用其它用户、物品特征以及上下文|
|逻辑回归|将推荐问题转换成类似 CTR 模型的二分类问题，将用户、物品、上下文等不同特征转换成特征向量，输入到回归模型到得到 CTR，然后再按照 CTR 排序并推荐|能够融合多种类的不同特征|模型不具备特征组合的能力，表达能力较差|
|FM|在逻辑回归的基础上，在模型中加入了二阶特征交叉部分，为每一维特征训练得到相应特征隐向量，通过隐向量计算内积，得到较差特征权重|相比逻辑回归，具备了二阶特征交叉能力，模型的表达能力增强了。|由于组合爆炸问题的限制，模型不已扩展到三阶特征交叉阶段|
|FFM|在 FM 基础上，加入“特征域”，使每个特征在在与不同城的特征交叉时，采用不同的隐向量|相比 FM，进一步增加了特征交叉的能力|模型的训练开销达到 O(n^2)的量级，训练开大|
|GBDT+LR|利用 GBDT 进行的自动化的特征组合，将原始特征向量转化成离散特征向量，并输入 LR 模型，进行最终的排序|特征工程模型化，是模型具备了更高阶特征组合能力| GBDT 无法进行完全的并行训练，更新的训练时间较长。|
|LS-PLM|首先对样本进行分片，在每个分片内部结构构建逻辑回归模型，将每个样本的个分片概率与逻辑回归的得分进行加权平均，得到最终的预估值|模型结构类似三层神经网络，具备较强的表达能力|模型结构相比深度学习模型仍比较简单，有进一步提高的空间|


## 3. 浪潮之巅 - 深度学习饿在推荐系统中的应用
### 传统模型 VS. 深度学习
* 深度学习模型表达能力更强，能够挖掘出更多数据中潜在的模式
* 深度学习模型结构非常灵活，能够根据业务场景和数据特点，灵活调整模型结构，使模型与应用场景完美契合。

### 深度学习模型演化关系
1. 改变神经网络的复杂程度：从简单的单层神经网络模型 AutoRec，到经典的深度神经网络结构 Deep Crossing（深度特征交叉），其主要的进化方式在于增加了深度神经网络的层数和结构复杂度。
2. 改变特征的交叉方式：改变了用户向量和物品向量互操作方式的 Neural CF，定义了多种特征向量交叉操作的 PNN （Product-based Neural Network）模型
3. 组合模型：Wide & Deep、Deep&Cross、DeepFM。思路是通过组合两种不同的特点、优势互补的深度学习模型。
4. FM 模型的深度学习演化版本：NFM、FNN
5. 注意力机制与推荐模型的结合：DIN
6. 序列模型与推荐模型的结合：DIEN
7. 强化学习与推荐模型的结合：DRN

### AutoRec 模型的特点和局限
* 模型从神经网络的角度出发，使用了一个单隐层的 AutoEncoder 泛华用户或物品评分，使模型具有一定的泛化能力和表达能力。
* 模型结构较为简单，存在的一定的表达能力不足的问题。 

### Deep Crossing 模型
* 完整的解决了特征工程、稀疏向量稠密化、多层神经网络进行优化目标你和等一些列深度学习饿在推荐系统中的应用问题。
* 分层
   * Embedding：将稀疏的类别特征转化为稠密的 embedding 向量
   * Stacking：将不同的 embedding 特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量。 
   * Multiple Residual Units 层：多层感知机。
   * Scoring：输出层，为了拟合优化目标而存在的。
      * 对于 CTR 这类二分问题，一般使用逻辑回归。
      * 对于多分类问题，一般采用 softmax 模型。 

### Neural CF ： CF 与深度学习的整合
* 混合了原始的 NeuralCF 模型和以元素积Wie互操作的广义矩阵分解模型。 
* Softmax 函数：解决了从一个原始的 n 维向量，向一个 n 维的概率分布映射的问题。
* 优势：利用神经网络理论上能够拟合任意函数的能力，灵活地组合不同的特征，按需增加或减少模型的复杂度。
* 不足：基于协同过滤的思想进行改造的，没有引入更多的特征。

### PNN 模型 ： 加强特征交叉能力
* 优势：强调了特征 Embedding 向量之间的交叉方式是多样的。
* 局限性：一定程度上忽略了部分的信息。 


### Wide&Deep 模型：记忆能力和泛化能力的综合
* Wide 部分让模型具有较强的记忆能力；Deep 部分让模型具有泛化能力。 
* Deep&Cross 模型
   * 使模型具有非线性学习能力
* 成功的关键
   * 抓住了业务问题的本质特点，能够融合传统模型记忆能力和深度学习泛化能力的优势。 
   * 模型结构并不复杂，比较在工程上实现、训练和上线，这加速了其在业界的推广和发展。 
   
### FM 与深度学习的结合
* FNN ： 用 FM 隐向量完成 Embedding 层初始化
* DeepFM：将 FM 与 Wide&Deep 整合
* NFM：FM 的神经网络化尝试
* 基于 FM 的深度学习模型的优点和缺点
   * 优点：经典多层神经网络的基础上加入有针对性的特征交叉操作，让模型具备更强的非线性表达能力。
   * 缺点：进一步提升的空间小。

### 注意力机制的引入
* AFM
* DIN

### DIEN：序列模型和推荐系统的结合
* DIEN

### 强化学习与推荐系统的结合
* DRN
* 行动、状态、反馈
* 可以在线学习。

### 总结
  
|模型名称|基本原理|特点|局限性|
|---|---|---|---|---|
|AutoRec|基于自编码器，对用户或物品进行编码，利用自编码器的泛化能力进行推荐|单隐层神经网络结构简单，可以实现快速训练和部署|表达能力差|
|Deep Crossing|利用 Embedding+多隐层+输出层 的经典深度学习框架，预完成特征的自动深度交叉|经典的深度学习推荐模型框架|利用全连接隐层进行特征交叉，针对性不强|
|NeralCF|将传统的矩阵分解中用户向量和物品向量的点积操作，换成有神经网络代替的互操作|表达能力加强版的矩阵分解|只是用了用户和物品id等属性，没有加入其他特征|
|PNN|针对不同特征领域的教槽操作，定义 内积、外积等多种积操作|在经典深度学习框架上模型对提高特征交叉能力|外积操作进行了近似化，一定程度上影响了其表达能力|
|Wide&Deep|利用 Wide 部分加强模型的记忆能力，利用 Deep 部分加强模型的泛化能力|开创了组合模型的构造方法，对深度学习美腿年模型的后续发展产生重大影响|Wide 部分需要人工进行特征组合的筛选|
|Deep&Cross|用 Cross 网络提点 Wide&Deep 模型中 Wide 部分|解决了 Wide&Deep 模型人工组合特征的问题|Cross 网络的复杂度较高|
|FNN|利用 FM 的参数来初始化深度神经网络的 Embedding 层参数|利用 FM 初始化参数，加快真个网络的收敛速度|模型的主结构比较简单，没有引针对性的特征交叉层|
|DeepFM|在 Wide&Deep 模型的基础上，用 FM 替换了原来线性 Wide 部分|加强了 Wide 部分的特征交叉能力|与经典的 Wide&Deep 模型相比，结构差别不明显|
|NFM|用神经网络替代 FM 中二阶隐向量交叉操作|相比 FM，NFM 的表达能力和特征交叉能力更强|与 PNN 模型结构非常相似|
|AFM|在 FM 的基础上，在二阶隐向量交叉的基础上对每个交叉结果加入了注意力得分，并使用注意力网络学些的注意力得分|不同交叉特征的重要性不同|注意力网络的训练过程比较复杂|
|DIN|在传统深度学习推荐模型的基础上引入了注意力机制，并利用用户行为历史物品和目标广告物品的相关性计算注意力得分|根据目标广告物品的不同，进行更有针对性的推荐|并没有充分利用处“历史行为”意外的其他特征|
|DIEN|将序列模型与深度学习推荐模型结合，使用序列模型模拟用户的兴趣进化过程|序列模型增强了系统对用户兴趣变迁的表达能力面试推荐系统开始考虑时间相关的行为序列中包含的有价值信息|血猎模型的训练复杂，线上服务的延迟较长，需要进行工程上的优化|
|DRN|将强化学习的思路应用于推荐系统，进行推荐建模型的线上时时学习和更新|模型对数据实时性的利用能力大大加强|线上部分较复杂，工程实现难度较大|


## Chapter 4：Embedding 技术在推荐系统中的应用
* Embedding 经历了从处理序列样本，到处理图像样本，再到处理异构的多特征样本的快速进化过程。

### 什么是 Embedding
* Embedding 就是用一个低维稠密的向量表示一个对象（object）。
* Embedding 向量能够表达相应对象的某些特征，同时向量之间的距离反映了对象之间的相似性。
* Embedding 技术对深度学习推荐系统的重要性
   * 推荐场景中大量使用 one-hot 编码对类别、id 特征进行编码，导致样本特征向量极度稀释。
   * Embedding 本身就是极其重要的特征向量。
   * Embedding 对物品、用户相似度的计算是常用的推荐系统的召回层技术。

### Word2vec - 经典的 Embedding 方法
* CBOW 模型
* Skip-gram 模型   

### Item2vec - Word2vec 在推荐系统领域的推广
* 与 Word2vec 不同在于，Item2vec 摒弃了时间窗口的概念年，认为序列中任意两个物品都相关，因此在 Itemvec 的目标函数中可以看到，其是两两物品的对数概率的和，而不仅是时间窗口内物品的对数概率之和。
* 广义的 Item2vec
   * 双塔模型
* 局限性：只能利用序列型数据。

### Graph Embedding - 引入更多的结构信息的图像嵌入技术
* DeepWak
* Node2vec
   * 结构性：BFS
   * 同质性：DFS
* EGES - 阿里巴巴的综合性 Graph Embedding 方法

### Embedding 与深度学习推荐系统的结合
* 方向
   * 1. 在深度学习网络中作为 Embedding 层，完成从高维稀疏特征向量到地位稠密特征向量的转换。 
   * 2. 作为预测训练的 Embedding 特征向量，与其他特征向量连接后，一同输入深度学习网络进行训练。 
   * 3. 通过计算用户和物品的 Embedding 相似度，Embedding 可以直接作为推荐系统的召回层或者召回策略之一。

### 局部敏感哈希 - 让 Embedding 插上翅膀的快速搜索方法
* 快速 Embedding 最近邻搜索
   * kd 树索引结构
   * 局部敏感哈希（Locality Sensitive Hashing，LSH）      
   * 准确率与召回率的权衡。

### 总结
|Embedding 方法|基本原则|特点|局限性|
|---|---|---|---|
|Word2vec|利用句子中词的相关性建模，利用单隐层神经网络获得词的 Embedding 向量|经典 Embedding 方法|仅能的针对词序列样本进行训练|
|Item2vec|吧 Word2vec 的思想扩展到任何序列数据上|将 Word2vec 应用到推荐领域|仅能针对序列样本进行训练|
|DeepWalk|在图结构上进行随即游走，生成序列样本后，利用 Word2vec 的思想建模|医用的 Graph Embedding 方法|随机游走进行抽样的针对性不强|
|Node2vec|在 DeepWalk 的基础上，通过调整随机游走权重的方式使 GraphEmbedding的结果在网络的同质性和结构性之间进行权衡|可以有针对性地挖掘不同的网络特征|需要较多的人工调参|
|EGES|将不同信息对应的 Embedding 加权融合后生成最终的 Embedding 向量|融合多种补充信息，解决 Embedding 的冷启动问题|没有较大的学术创新，更多的是从工程角度解决多 Embedding 融合的问题|
|局部敏感哈希|利用局部敏感哈希的原理进行快速的 Embedding 向量最近邻搜索|解决利用 EMbedding 作为推荐系统召回层的快速计算问题|存在小概率的最近邻遗漏可能，需要机型较多的人工调参|


## Chapter 5：多角度审视推荐系统
* 抓住问题的核心，更要从整体上思考推荐问题。

### 5.1 推荐系统的特征工程
* 构建推荐系统特征工程的原则
   * 特征的本质其实是对某个行为过程相关信息的抽象表达。
   * 信息损失。
   * 原则：尽可能地让特征工程抽取出的一组特征能够保留推荐环境及其用户行为过程中的所有有用信息，尽量摒弃冗余信息。
* 推荐系统中的常用特征
   * 用户行为数据
   * 用户关系数据
   * 属性、标签数据
   * 内容数据
   * 上下文信息
   * 统计类特征
   * 组合类特征
* 常用的特征处理方法
   * 1. 连续型：归一化；离散化。
   * 2. 类别性特征：multi-hot 编码。    
* 特征工程与业务理解

### 5.2 推荐系统召回层的主要策略
* 召回层和排序层的功能特点
   * 召回层：待计算的候选集和大、速度快、模型简单、特征数较少，金陵让用户感性的物品在这个阶段能被快速找回，即保证相关物品的召回率。
   * 排序层：首要目标是得到精准的排序结果。需处理物品数量少，可利用较多特征，使用比较复杂的模型。
* 多路召回策略：与业务强相关
   * 热门
   * 兴趣标签
   * 协同过滤
   * 最近流行
   * 朋友喜欢 
       
* 基于 Embedding 的召回方法
   * 在利用 Embedding 召回的过程中，考虑到了多路召回的多种策略。
   * Embedding 召回的另一个优势在于评分的连续性。

### 5.3 推荐系统的实时性
* 模型更新得越频繁，实时性越好，损失越小，效果越好。
* 实时性的重要之处
   * 1. 特征的实时性：推荐系统的更新速度越快，代表用户最近习惯和爱好的特征更新越快，越能为用户进行更有时效性的推荐。 
      * 客户端实时特征
      * 流计算平台的准实时特征处理
      * 分布式批处理平台的全量特征处理。
   * 2. 模型的实时性：推荐系统更新得越快，模型约容易发现最新流行的数据模式，越能让模型快速抓住最新的流行趋势。
      * 全量更新
      * 增量更新
      * 在线学习（online learning）
      * 局部更新
      * 客户端模型实时更新

### 5.4 如何合理设定推荐系统中的优化目标
* 如果意向技术本身是心音的、现金的，但应用的方向与实际需要的方向有偏差，那这项技术的成果不可能是显著的。
* YouTube 以观看时长为优化目标的合理性
* 模型优化和应用场景的统一性
* 优化目标是和其他团队的接口行工作

### 5.5 推荐系统中比模型结构更重要的是什么？
* 理解自己的用户场景，熟悉自己的数据特点才是重要的。
* 在构建推荐模型过程中，从应用场景触发，基于用户行为和数据的特点，提出合理的改进模型的动机才是重要的。
* 真正的银弹是你对用户行为和应用场景的观察，基于这些观察，改进出最能表达这些观察的模型结构。
* 从用户的角度思考问题，构建模型。 

### 5.6 冷启动的解决方法
* 冷启动的分类：
   * 用户冷启动
   * 物品冷启动
   * 系统冷启动
* 冷启动的策略
   * 基于规则的冷启动
   * 丰富冷启动过程中可获得的用户和物品特性
      * 用户的注册信息
      * 三方的 DMP 信息
      * 物品的内容特征
      * 引导用户输入的冷启动过程
   * 利用主动学习、迁移学习和“探索和利用”机制   
      * 主动学习：主动向外界发出询问，获得反馈
      * 迁移学习：在某领域知识不足的情况下，迁移其他领域的数据或知识，用于本领域的学习。
      * 探索与利用的机制
         * UCB
* 探索与利用
   * 方法
      * 1. 传统的探索与利用：Thompson Smapling、 UCB
      * 2. 个性化的探索与利用方法
         * LinUCB
      * 3. 基于模型的探索与利用方法
      * 4. 探索与利用 机制在推荐系统中的应用
         * 1. 物品冷启动
         * 2. 发觉用户新兴趣
         * 3. 增加结果多样性

## Chapter 6：深度学习推荐系统的工程实现
### 6.1 推荐系统的数据流
* 批处理大数据架构
   * 分布式 + MR
* 流计算大数据架构
   * 滑动窗口
   * Storm、Spark Streaming、Flink
* Lambda 架构
   * 实时流和离线处理。
   * 实时流保持了流计算架构，保障了数据的实时性；离线处理部分则一批处理的方式为主，保障了数据的最终一致性。
* Kappa 架构
   * everything is stream
   * 原始数据存储 + 数据重播
   * 目前业界仍以 Lambda 为主，趋势是向 Kappa 架构靠拢。
* 新增了被称为新一代的 Unified 大数据架构，其在 Lambda 或 Kappa 架构上的流处理层新增了机器学习层，将机器学习和数据处理融为一体，别看做推荐系统和大数据平台的深度整合。

### 6.2 推荐模型离线训练之 Spark MLlib
* DAG
* 随机森林的模型结构特点决定了其可以完全进行数据并行的魔性训练，而 GBDT 的结构特点决定了数之间只能进行串行的训练。
* **同步阻断式**
* 并行训练的局限性
   * 1. 采用全局广播的方式，在每轮迭代之前广播全部的模型参数
   * 2. 采用阻断式的梯度下降方式，每轮梯度下降由最慢的节点决定
   * 3. Spark MLlib 并不支持复杂深度学习网络结构和大量可调超参。

### 6.3 推荐模型离线训练之 Parameter Server
* Parameter Server 由 Server 和 Worker 节点组成
   * Server 节点的主要功能是保存模型参数、接受 worker 节点计算出的具备梯度、火鬃计算全局梯度，并更新模型参数
   * wokrer 接地那的主要功能是保存部分训练数据，从 server 节点拉去最新的模型参数，根据训练数据计算局部梯度，上传给 server节点。
* **异步非阻断**
   * 加速了模型的训练速度，但带来了模型一致性的损失。
* 多 server 节点的协同和效率问题
   * server 集群内的机器采用一致性哈希。
* 总结
   * 用异步非阻断的分布式梯度下降策略替代同步阻断式的梯度下降策略。
   * 实现多 server 节点的架构，避免单 master 节点带来的带宽瓶颈和内存瓶颈。
   * 使用一致性哈希、参数范围拉取、参数范围推送等工程手段实现嘻嘻的最小传递，避免广播操作带来的全局性网络同步和带宽浪费。       
* parameter Server 往往作为 MXNet、TensorFlow 的一个组件。

### 6.4 推荐模型训练之 TensorFlow
* 深度学习矿建：Google TensorFlow、Amazon MXNet、Facebook PyTorch、MicoSoft CNTK。   
* 模型构建、并行训练、上线服务。
* 存在依赖关系的任务节点或者子图之间需要串行执行，不存在依赖关系的任务节点或者子图支架可以并行执行。
* DCG
* TensorFlow 的单机训练与分布式训练
   * CPU + GPU
   * CPU 主要负责数据和任务的调度
   * GPU 负责计算密集度高的张量运算。
* TensorFlow 要点：
   * 1. TensorFlow 直译为张量流动，主要原理是将模型悬链过程转换成任务关系图，让数据已张量的形式在任务关系图中流动，完成整个训练
   * 2. TensorFlow 基于任务关系图进行任务调度和并行计算。
   * 3. 对于分布式 TensorFlow 来说，其并行训练分为两层，一层是基于 Paramter Server 架构的数据并行训练过程；另一层是每个 worker 节点内部，CPU + GPU 任务级别的并行计算过程。 

### 6.5 深度学习推荐模型的上线部署
* 预存推荐结果或 Embedding 结果
* 自研模型线上服务平台
   * TensorFlow 等通用平台为了灵活性和通用性的要求，需要支持大量冗余的功能，导致平台过重，难以修改和定制。
   * 模型的需求比较特殊时，大部分深度学习框架无法支持。
   * 自研的弊端也显而易见：周期长。
* 预训练 Embedding  + 轻量级线上模型
   * 业界很多公司采用：复杂网络离线训练、生成 Embedding 存入内存数据库、线上是实现逻辑回归模型或浅层神经网络等轻量级模型你和优化目标。 
* 利用 PMML转换并部署模型
   * PMML： 预测模型标记语言（Predictive Model Markup Language）
         
### 6.6 工程与理论之间的权衡
* 在现有实际条件的制约下，以工程完成和技术落地为目标，寻找并实现最优的解决方案。 
* Redis 容量和模型上线方式之间的权衡
   * 1. 模型参数规模要尽量小
   * 2. 线上预估所需的特征数量不能无限制地增加，要根据重要性做一定的取舍。
* 思路
   * 1. 对于千万甚至更高量级的特征维度，理论上参数的数量级也在千万级，线上服务是很难支持这种级别的数据量的，这就要求工程商关注模型的稀疏性，关注主要特征，设计大量次要特征，舍弃一定的模型预测准确度提升线上预估的速度，减小工程资源消耗。
   * 2. 增强模型稀疏性的关键点有哪些？加入 L1 正则化项，采用 FTRL 等稀疏性强的训练方法。
   * 3. 实现目标的技术途径有多重，在无法确定那种技术效果更佳的情况下，实现所有备选方案，通过离线和在线的指标进行比较观察。
   * 4. 根据数据确定最终的技术途径，完善工程实现。
* 研发周期限制和技术选型的权衡
   * 技术途径：
      * 1. 集中团队力量完成 spark 到 TensorFlow 的迁移，在新平台上进行新模型和新功能的研发。
      * 2. 并行。（实际选择，迭代。）
* 硬件平台环境和模型结构间的权衡
   * 优化
      * 1. 程序本身的优化。
      * 2. 技术上的取舍。   
* 处理好局部与整体的关系


## Chapter 7：推荐系统的评估
* 评估体系的重要性
   * 1. 推荐系统评估所采用的指标直接决定了推荐系统的优化方向是否客观合理。 
   * 2. 推荐系统评估是机器学习团队与其他团队沟通合作的接口性工作。
   * 3. 推荐系统评估指标的选取直接决定了推荐系统是否符合公司的商业目标与发展愿景。
* 多维度探讨推荐系统评估的方法和指标
   * 1. 离线评估的方法和指标
   * 2. 离线仿真评估方法 —— replay（重播评估法）
   * 3. 线上 A/B 测试方法和线上评估指标
   * 4. 快速线上评估测试方法 —— Interleaving（间隔插值测试法）
   
### 7.1 离线评估方法与基本评价指标
* 方法
   * 1. holdout 检验
   * 2. 交叉检验
   * 3. 自助法
* 评估指标（更多的是作为预测模型，而不是实际的排序模型）
   * 1. 准确率
   * 2. 精确率 与 召回率
      * F1 score
   * 3. 均方根误差
      * RMSE（Root Mean Square Error）均方根误差
      * MAPE（Mean Absolute Percent Error）平均百分比误差
   * 4. 对数损失函数 （LogLoss）

### 7.2 直接评估推荐序列的离线指标   
* P-R 曲线
   * AUC 越大，排序模型的性能越好。
* ROC 曲线
   * the Receiver Operating Characteristic 曲线。受试者工作曲线。
   * FPR、TPR
* 平均精度均值
   * mean Average Precison，mAP
* 合理选择评估指标   
   * 归一化折扣累计收益（Normalized Discounted Cumulative Gain，NDCG）
   * 覆盖率
   * 多样性
   * 进行高效的里县实验才是李先评估的正确打开方式。

### 7.3 跟接近线上环境的离线评估方法 —— Replay
* 模型评估的逻辑闭环
   * 1. 什么样的模型是好模型
   * 2. 如何评估模型的商业价值和商业指标
   * 3. 如何在离线华景下得到线上 A/B 测试的评估指标
   * 4. 设是好的离线模型评估方法   
* 离线评估的重点是让离线评估的结果能够尽量接近线上结果
* 动态离线评估方法
   * Replay
      * 强化学习

### 7.4 A/B 测试与线上评估指标
* 何为 A/B 测试
   * 离线评估的局限
      * 1. 离线评估无法完全消除数据有偏（data bias）现象的影响
      * 2. 离线评估无法完全还原线上的工程环境
      * 3. 线上系统的某些商业指标在离线评估中无法计算
* A/B 测试的“分桶”原则
   * 层与层之间的流量“正交”
   * 同层之间的流量互斥

* 线上 A/B 测试的评估指标
   * 指标应该与线上业务的核心指标保持一致。

|推荐系统类别|线上 A/B 测试评估指标|       
|电商类|点击率、转化率、客单价（用户平均消费金额）|
|新闻类|留存率（x 日后仍活跃用户数/x 日前的用户数）、平均停留时长、平均点击个数|
|视频类|播放完成率（播放时长/视频时长）、平均播放时长、播放总时长|


### 快速线上评估方法：Interleaving
* 使用 Interleaving 方法进行测试的时候，必须考虑位置偏差的存在，避免来自算法 A 的视频总是排在第一位。
* Interleaving 方法无法完全替代 A/B 测试。如果希望得到更全面、真实的线上测试指标，则 A/B 测试是最权威的测试方法。

### 7.6 推荐系统的评估体系
* 离线评估 -> Replay方法 -> Interleaving 方法 -> 线上 A/B 测试
* 步骤：
   * 通过离线评估快速验证模型改进思想，提高模型改进效率
   * 离线仿真，模拟线上环境
   * 在线快速测试，候选算法快速筛选
   * 最终确定新模型是否上线


## Chapter 8：深度学习推荐系统的前沿实践
### Facebook 的深度学习推荐系统
1. 2014 GBDT + LR
2. 2019 DLRM
   * 特征工程
      * 一类是：将类别、id 类特征用 one-hot 编码生成的稀疏特征
      * 一类是：数值型连续特征
   * Embedding 层
      * 特征转换成 one-hot 向量之后，用 Embedding 层将其转换成维度为 n 的 Embedding 向量。
   * 神经网络层（NNs）
   * 特征交互层（interactions 层）
   * 目标拟合层

### Airbnb 基于 Embedding 的实时搜索推荐系统
* 工程与理论结合
* 业务与知识结合

### YouTube 深度学习视频推荐系统

### 阿里巴巴深度学习推荐系统的进化
1. 2012 LS-PLM
2. 2017 DIN
3. 2018 DIEN
4. 2019 多通道兴趣记忆网络（Multi-channle user Interest Memory Network，MIMN）
5. 总结
   * 1. 工程实践性很强
   * 2. 对用户行为的观察非常精准
   * 3. 模型的微创新

## Chapter 9：构建属于你的推荐系统知识框架
* 技术方案永远是多元的，不可能是唯一的。
* 从业者要求
   * 1. 知识：具备基本的推荐系统领域相关知识
      * 主要指推荐系统相关知识和理论的储备，比如主流的推荐模型、Embedding 的主要方法等。
   * 2. 工具：具备变成能力，了解推荐系统相关的工程实践工具
      * 运用工具将推荐系统的知识应用于实际业务的能力，推荐系统相关的工具主要包括 TensorFlow、PyTorch 等模型训练工具，Spark、Flink 等大数据处理工具，以及一些模型服务相关的工具。
   * 3. 逻辑：具备算法基础，思考的逻辑性、条理性较强
      * 举一反三的能力，解决问题的条理性，发散思维的能力，聪明程度，运用算法的掌握程度。
   * 4. 业务：对推荐系统的业务场景有所了解
      * 理解推荐系统的应用场景、商业模式；从业务中发现用户的动机，制定相应的优化目标并改进算法的能力。

