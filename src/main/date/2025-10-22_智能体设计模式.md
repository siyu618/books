## 智能体设计模式

### 1. 提示链 Prompt Chaining
* 提示链将复杂任务拆解为一些列小型、聚焦不走，亦称为流水线模式。 
* 每步链条包函一次 LLM 调用或处理逻辑，以上一步输出为输入。 
* 该模式提升了与语言模型复杂交互的可靠性和可管理性。
* LangChain/LangGraph、Google ADK 等框架为多步序列定义、管理和执行提供了强大工具。 


### 2. 路由 （routing）
* 路由使得智能体可根据条件动态决策下一步流程。 
* 智能里可以处理多样输入并自适应行为，突破现行执行限制。 
* 路由逻辑可由LLM、 规则系统、或 Embedding 相似度实现。 
* LangGraph、Goolge ADK 等框架提供结构化路由定义与管理方式，架构风格各异。 


### 3. 并行化
* 并行化湿一种通过并罚执行独立任务提升效率的设计模式。 
* 尤其适用于涉及外部资源（如 API 调用）等待的场景。 
* 并发/并行架构会增加设计、调试和日志等开发复杂度与成本。
* LangChain、Google ADK 等框架均支持并行定义与管理。 
* LCEL 中 RunnableParallel 是并行运行多个 runnable 的关键构造
* Google ADK 可通过 LLM 驱动的委托，实现协调智能体并行处理子任务。 
* 并行化可显著降低整体延迟，让智能体系统在否认砸任务下更具响应性。 


### 4. 反思
* 反思模式的核心优势是能叠戴自我纠错和优化输出，显著提升质量、准确性和复杂指令。 
* 包含执行、评估/批判和优化的反馈循环，适用于高质量、准确或复杂输出任务。 
* 强大的实现方式是生产者- 批评者模型，独立智能体评估初始输出，分工提升客观行和结构反馈。 
* 但需权衡延迟和计算成本增加，以及模型上下文窗口溢出或 API 限流风险。 
* 完整迭代反噬需要有状态工作流（如 LangGraph），单步反思可在 LangChain 用 LCEL 实现输出批判和优化。 
* Google ADK 可通过顺序工作流实现反思，一智能体输出由另一智能体批判，支持后续优化。 
* 该模式让智能体具备自我纠错和持续性能提升能力。 

### 5. 工具使用（函数调用）
* 工具使用（函数调用）让智能体与外部系统交互，获取动态信息。 
* 需要定义工具并清晰描述参数，便于 LLM 理解。 
* LLM 决定何时使用工具并生成结构化调用请求。 
* 智能体框架实际执行工具调用并返回结果。 
* 工具使用时构建能执行现实动作、提供最新信息智能体的关键。 
* LangChain 用 @tool 装饰简化工具定义，并提供 create_tool_calling_agent 和智能体 execuor 构建工具智能体。 
* Google ADK 内置了如 Google 搜索、 代码执行、 Vertex AI Search 等实用工具。 


### 6. 规划
* 规划使智能里能够将复杂目标拆解为可执行的、顺序化的步骤。 
* 该模式对于处理多步骤任务、工作流自动化和复杂环境导航至关重要。 
* 大语言模型可根据任务描述生成逐步规划，实现自动化分解与执行。 
* 明确提示货设计任务要求规划步骤，可在智能体框架中激发此类行为。 
* Google Deep Search 是一个智能体，利用 Google 搜索工具为用户分析信息来源。

### 7. 多智能体协作
* 多智能体协作即多个智能体共同实现目标。 
* 该模式利用专长分工、任务分布于智能体通信。 
* 协作形式包括顺序交接、并行处理、辩论或层级结构。 
* 适用于需要多领域专长或多阶段复杂问题。 

### 8. 记忆管理
* 记忆对于智能体跟踪信息、学习和个性化交互至关重要。 
* 对话式 AI 以来短期基于维持单词就聊天上下文，长期记忆则跨会话存知识。 
* 短期记忆（即使信息）是临时的，常受 LLM 上下文窗口或框架传递方式限制。 
* 长期记忆（持久信息）通过外部存储（向量数据库）保存，并通过检索访问。 
* ADK 框架由专用组件： Session、State、MemeoryService 管理记忆。 
* ADK 的 SessionService 管理绘画生命周期，包括历史（events）和临时数据（state）。
* ADK 的 Session。state 是临时数据字典，前缀（suer:\app:\temp:)标明数据归属和持久性。 
* 在 ADK 中，推荐通过 EventActions.state_delta 或 output_key 更新 state，不要直接修改 state 字典。 
* ADK 的 MemoryService 用于长期存储和检索信息，常通过工具实现。 
* LangChain 提供如 ConversationBufferMemeory 等工具， 自动将单次对话历史注入提示，实现即时上下文。 
* LangGraph 提供高级长期记忆，通过 store 保存和检索语义事实、情景经历或可更新规则，跨用户会话持久化。 
* Memory Bank 是托管服务，自动提取、存储和回忆用户信息，实现个性化、持久对话， 支持 ADK、LangGraph、CrewAI等框架。 


### 9. 学习与适应
* 学习与适应让智能体功过经验不断提升能力， 应对新情况。 
* 适应 是智能体因学习而表现出的行为或知识变化。 
* SICA 智能体通过自我修改代码实现自我改进，催生了智能体编辑器和 AST 符号定位器等工具。 
* 专用子智能体和监督者有助于自我改进系统分解大任务并保持进度。
* LLM 的上下文窗口结构（系统提示、核心提示、助手消息）对智能体效率至关重要。 
* 此模式适用于需要在不断变化、不确定或需要个性化环境中运行的智能体。 
* 构建能学习的智能体通常需要继承机器学习工具并管理数据流。 
* 配备基础编码工具的智能体可自主编辑自身代码，从而提升基准任务表现。 
* AlphaEvolve 是 Google 的智能体，结合 LLM 和进化框架， 实现算法自主发现与优化， 推动基础研究和实际应用。 

### 10. 模型上下文协议（MCP）
* MCP 是开放标准，规范 LLM 与外部应用、数据源和工具的通信。 
* 采用 CS 架构，定义资源、Prompt 和工具的暴露与消费方式。 
* ADK 支持消费现有 MACP 服务器，也可将自身工具包卤味 MCP 服务。 
* FactMCP 建委 MCP 服务器开发，尤其适合 Python 工具的快速集成。 
* MCP Genmedia 工具支持智能体即成 Google Cloud 升华成呢个是媒体服务（Imagen、Veo）
* MCP 让 LLM 和智能体能访问真实世界系统、动态信息，并执行超越文本生成的操作。 


### 11. 目标设定与监控
* 目标设定与监控赋予智能体目标感和进度追踪机制。 
* 目标应具体、可衡量、可达成、相关且有时间限制（SMART）
* 明确指标和成功标准是有效监控的关键。 
* 监控包括观察智能体行为、环境状态和工具输出。 
* 监控反馈回路让智能体能自适应、修正计划或升级问题。 
* 在 Google 的 ADK 中，目标通常通过智能体指令传递，监控则通过状态管理和工具实现。 


### 12. 异常处理与恢复
* 异常处理与恢复是构建健壮可靠智能体的基础。 
* 该模式包括错误检测、优雅处理和恢复策略。 
* 错误检测可通过验证工具输出、检查 API 错误码和超时实现。 
* 处理策略包括日志记录、充实、备用方案、优雅降级和通知。 
* 恢复聚焦于诊断、自我修正或升级，恢复稳定运行。 
* 该模式确保智能体在不可预测的这是环境中依然高效运行。 


### 13. 人类参与环节
* Human-in-the-loop （HITL）将人类智能和判断力融入 AI 工作流。 
* 在复杂或高风险场景下，安全、伦理和效果至关重要。 
* 关键方面包括人类监督、敢于、学些反馈和决策增强。 
* 升级策略让智能体知道何时应交由人类处理。 
* HITL 支持负责任的 AI 部署和持续改进。 
* HITL 的主要缺点是可扩展性不足，需要准确性与处理像之间的权衡，并高度依赖领域专家的有效干预。 
* 实施过程中还需要培训人工操作员生成数据，并通过你明湖啊处理敏感信息以应付隐私挑战。 


### 14. 知识检索（RAG）
* 知识检索 （RAG）让 LLM 能访问外部、最新、专有信息。 
* 包含检索（搜索知识库相关片段）和增强（将片段加入 LLM 提示）两步。 
* RAG 帮助 LLM 客服训练数据果实、减少幻觉， 实现领域知识集成。 
* RAG 支持可以归因答案，响应基于检索来源。 
* GraphRAG 李忠知识图谱理解信息之间的关系，能回答需要多源综合的复杂问题。 
* 智能体 RAG 通过智能主体主动推理、验证和精炼外部知识，确保大难更准确可靠。 
* 实践应用涵盖企业搜索、客户支持、法律检索、个性化推荐等场景。 

### 15 智能体间通信（A2A）
* Google A2A 协议是一项开放、基于 HTTP 的标准，促进不同框架智能体间的通信与协作。 
* AgentCard 是智能体的数字身份，便于其他智能体自动发现和理解起能力。 
* A2A 支持同步请求 - 响应（tasks/send）和流式更新（tasks/sendSubscribe），满足不同通信需求。 
* 协议支持多轮对话，包括 input-required 状态，Agent 可请求不从信息并保持上下文。 
* A2A 鼓励模块化架构，专用智能体可独立运行与不同端口，实现系统可扩展和分布式部署。 
* Trickle AI 等工具可可视化和跟踪 A2A 通信，便于开发者监控、调试和优化多智能体系统。 
* A2A 专注于智能体间任务和工作流管理， MCP 则为 LLM 与外部资源交互提供标准接口。 


### 16. 资源感知优化
* 资源嘎吱优化至关重要： 智能体可动态管理计算、实践和财务资源，依据实时约束作出模型和执行路径的决策。 
* 多智能体架构实现可扩展性： Google ADK 提供的多智能体框架，支持模块化设计，不同智能体（答题、路由、批判）各司其职。 
* 动态 LLM 路由：路由稚嫩体根据查询复杂度和预测分流到 Gemini Flash（简单）或Gemini Pro（复杂），优化成本和性能。 
* 批判智能体功能：专用批判智能体提供自我纠错、性能监控和路由逻辑优化反馈， 提升系统效能。 
* 反馈与灵活性优化：评估能力和模型即成灵活性促成系统自适应性和自我提升。 
* 其他资源优化技术： 包括自适应工具选择、上下文剪枝与摘要、主动资源预测、多智能体成本敏感探索、能效部署、并行与分布式计算、学些行资源分配策略、优雅降级与回退机制、关键任务优先级分配等。 


### 17. 推理技术
* 显式推理让智能体能制定透明多步计划，是自主行动和用户信任的基础。 
* ReAct 框架赋予智能体核心操作循环，时期能动态行动并与环境交互。 
* 推理扩展定律表明智能体性能不仅取决于模型大小，还取决于分配的思考时间，实现高质量的自主行动。 
* 链式思维（COT）是知恩感体的内部独白，通过分布规划将复杂目标拆解为可执行序列。 
* 树式思维和自我纠错赋予智能体深度思考能力，可评估多种策略、纠错并优化方案。 
* 协作框架如辩论链（COD）推动单体到多智能体系统，团队协作能解决更复杂常见问题。 
* Deep Reaearch 等应用展示了这些技术如何让智能体自主执行复杂、长期任务，如深入调查。 
* MASS 框架自动优化智能体提示和交互结构，确保多智能体系统整体性能最优。 
* 集成这些推理技术，打造真正自主、可托付的智能体，能独立规划、行动和解决复杂问题。 


### 18. 护栏与安全模式
* 护栏是构建负责人、合规、安全智能体的基础，防止有害、偏见或跑题输出。 
* 可在输入验证、输出过滤、行为越苏、工具限制、外部审核等环节实施。 
* 多种护栏技术组合最为稳健。 
* 护栏需持续监控、评估和优化，是一个分型和用户变化。 
* 有效护栏对维护用户信任和智能。 
* 构建可靠、工程机智能体的最佳方式，是将其视为复杂软件系统，应用传统系统几十年成熟的工程实践，如容错设计、装体啊管理和全面测试。 


### 19. 评估与监控
* 智能体评估超越传统测试，需要持续亨利那个骑在实际环境中的有效性、效率和合规。 
* 典型应用包括身缠环境性能最终， A/B测试、合规审计、漂移和异常检测。 
* 基础评估关注响应准确性，实际场景需要延迟监控、LLM TOken 用量等更复杂指标。 
* 轨迹评估关注智能体行为序列，将实际步骤与理想路径对比， 发现错误和低效。 
* ADK 提供结构话评估方法，支持单元测试和集成测试，均定义预期行为。 
* 评估可通过 Web UI 交互测试， pytest 集成 CI/CD、命令行自动化执行。 
* 为提升 AI 在复杂高等线任务中的可靠性，需从简单提示专项正式合同，明确定义可交付物范围、支持协商、分解和自我验证，将智能体转变为柯文哲系统。 


### 20. 优先级排序
* 优先级排序让智能体在复杂多元环境下搞笑运作。 
* 智能体通过紧急性、重要性、依赖关系等标准排序任务。 
* 动态优先级调整使智能体能师是响应环境变化。 
* 优先级排序可应用于战略目标和及时战术决策等多个层级。 
* 有效的优先级排序提升智能体效率和操作稳健性。


### 21. 探索与发现
* AI 的探索与发现能力使知恩感体能主动获取新信息和可能性，适应复杂动态环境。 
* Google Co-Scientist 等系统展示了智能体如何自主生成假设和设计实验。 
* Agent Laboratory 的多智能体框架通过自动化文案综述、实验和报告撰写提升科研效率。 
* 这些智能体通过挂历计算密集型任务，增强认为创造里和问题解决能力，加速创新和发现。 


 




