redis 设计与实现

***Chapter 2 简单动态字符串***

2.1 SDS（Simple Dynamic String）定义
   ```c
   sds.h/sdshdr
   struct sdshrd {
      int len; // 记录buf中已经使用的字节的数量，等于sds所保存字符串的长度
      int free; // 记录buff中未使用的字节的数量
      char buf[]; // 字节数组，用于保存字符串，总长度：len + free + 1 （'\0'）
   }
   ```

2.2 SDS 与C字符串的区别
   * STRLEN 常数复杂度获取字符串长度 O(1)
   * 杜绝缓冲区溢出，strcat首先看时候能否放得下，不能则先扩容
   * 减少修改字符串是带来的内存重分配次数
      * 空间预分配
         1. 对sds修改之后，如果sds长度（len属性）小于1MB，则程序分配与len属性相同大小的未使用空间，则buf长度为 len + len + 1
         1. 如果长度大于1MB， 则分配1MB未使用空间，buf长度为 len + 1MB + 1 byte
      * 惰性回收
   * 二进制安全
   * 兼容部分c函数


***Chapter 3 链表*** 

3.1 链表和链节点的实现
   ```
   adlist.h/listNode
   typedef struct listNode {
      struct listNode *prev; // 前置节点
      struct listNode *next; // 后置节点
      void *value;  // 节点的值
   } listNode;
   ```
   ```
   typedef struct list {
      listNode *head; // 头节点
      listNode *tail; // 尾节点
      unsigned long len; // 链表包含的节点数
      void* (*dup)(void *ptr); // 节点值复制函数
      void (*free)(void *ptr); // 节点值释放函数
      int (*match)(void *ptr, void *key); // 节点值对比函数
   } list;
   ```
   * 特性
      1. 双端链表
      1. 无环
      1. 带有头指针和尾指针
      1. 带链表长度计数器  
      1. 多态
   * 使用场景
      * 列表键，发布订阅，慢查询，监视器

***Chapter 4 字典***

4.1 字典的实现
   ```
   dict.h/dictht
   typedef struct dictht {
      dictEntry **table; //哈希表数组
      unsigned long size; //哈希表大小，table数组的大小
      unsigned long sizemask; //哈希表大小掩码，用于计算索引值，值总为 size-1
      unsigned long used; // 该哈希表已有的节点的数量
   } dictht;
   ```
   ```
   dict.h/dictEntry
   typedef struct dictEntry {
      void *key; // key
      union {
         void * val; //
         uint64_t u64; //
         int64_t s64; //
      } v; //   value
      struct dictEntry *next; // next
   } dictEntry;
   ```
   ```
   dict.h/dict
   typedef struct dict {
      dictType *type; // 特定类型函数
      void *privdata; // 似有数据
      dictht ht[2]; // 哈希表，平时只有ht[0]在使用，进行rehash时，两个同时使用
      int rehashidx; // rehash索引，没有在进行rehash时，值为-1；

   } dict;
   ```
   * type属性和privadata属性是针对笔筒类型的键值对，为创建多态字典而建设的
      * type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键对值的函数，redis会为不同用途不同的字典设置不同类型的特定函数
      * privdata属性则保存了需要传给那些特定类型函数的可选项
   ```
   typedef struct dictType {
      // 计算hash值的函数
      unsigned int (*hashFunction)(const void *key);
      // 复制key的函数
      void* （*keyDedup)(void *privdata, const void *key);
      // 复制value的函数
      void* (*valDup)(void *privdata, const void *obj);
      // 对比key的函数
      int (*keyCompare)(void *privdata, const void *key1, const void *key2);
      // 销毁key的函数
      void (*keyDestructor)(void *privdata, void *key);
      // 销毁value的函数
      void (*valDestructor)(void *privdata, void *obj);
   } dictType;
   ```

4.2 hash算法
   * 使用MurmurHash2哈希算法
   ```
   hash = dict->type->hashFunction(key);
   index = hash & dict->ht[x].sizemask;
   ``` 
 
4.3 解决key冲突
   * 采用链地址法（separate chaining）

4.4 rehash
   * rehash 步骤：
      1. 为字典的ht[1]哈希表分配空间，这个哈希表的大小取决于要执行的操作，以及ht[0]当前包含的键值对的数量（即ht[0].userd）    
         * 如果执行的是扩展操作，则ht[1]的大小为第一个大于等于ht[0].used * 2 的pow(2,n)
         * 如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的pow(2,n)
      1. 将保存在ht[0]中的所有的键值对rehash到ht[1]上面
         * rehash是指重新计算key的hash和index，然后将键值对放置到ht[1]中指定位置上
      1. 当ht[0]包含的所有键值对都迁移到ht[1]之后（ht[0]为空），释放ht[0], 将ht[1]设置为ht[0]，并在ht[1]新建一个空白hash表，为下一次rehash做准备
   * hash表的扩展与收缩
      * 扩展操作发生的条件（任一满足即可）：load_factor = ht[0].used / ht[0].size
         1. 服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载引子大于等于1
         1. 服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令， 并且哈希表的负载引子大于等于5
   * 渐进式rehash
      * rehash不是一次性、集中式地完成的，而是分多次、渐进式的完成的
         * 原因在于，如果hash表很到的话，rehash需要很长时间，可能知道服务器在一段时间内停止服务
      * 步骤
         1. 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个hash表
         1. 在字典中维持一个索引计数器变量rehashidx， 并将其设置为0，表示rehash开始工作
         1. 在rehash进行期间，每次对字典执行添加、删除、查找或更新操作时， 程序除了执行置顶的操作意外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增1.
         1. 随着字典操作的部队执行，最终在某个时间点上， ht[0]的所有键值对都被rehash到ht[1]，这时程序将rehashidx属性设为-1，表示rehash操作结束
      * rehash执行期间的哈希表操作
         * 字典的delete、find、updatedd等操作会在两个哈希表上进行
   * 字典用于数据库和哈希键

***Chapter 5 跳跃表***

   跳跃表（skiplist） 是一种有序数据结构，通过在每个几点中维持多个指想其他节点指针，从而达到快速访问的目的。
   跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性来批量处理节点
   redis 中使用skiplist的地方：实现有序集合键、集群节点中用于内部数据结构

5.1 跳跃表的实现
   ```
   redis.h/zskiplistNode
   typedef struct zskiplistNode {
      struct zskiplistLevel {
        struct zskiplistNode *forward; // 前进执行
        unsigned int span; // 跨度
      } level[]; // 层 ： 一般来说层越多，方悦其他节点的速度就越快
      struct 在skiplistNode *backward; //后推指针
      double score; // 分值
      robj *obj;   // 成员对象
   } zskiplistNode;
   ```
   ```
   typedef struct zskiplist {
       struct zskiplistNode *head;
       struct zskiplistNode *tail;
       unsigned long length; // 节点数量
       int level; // 表中层数最大的节点数量
   } zskiplist;

   ```

***Chapter 6 整数集合***

6.1 整数集合的实现
   ```
   typedef struct intset {
       uint32_t encoding; // 编码方式
       uint32_t length; // 集合中包含元素数量
       int8_t contents[] // 保存元素的数组, 其中元素是有序的
   } intset;
   ```

6.2 升级
   * 当加入的新元素的类型比整数集合现有的类型都养长时，整数集合需要先进行升级（upgrade）
   * 升级的步骤
      1. 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。
      1. 将底层数组现有的所有元素都转换与新元素相同的类型，并将类型转换后的元素放置到正确的位上，而且在防止元素的过程中，需要继续维持底层数组的有序性值不变
      1. 将新元素添加到底层数组里面
   * 升级的好处
      * 提升灵活性
      * 节约内存

6.3 降级
   * 不支持降级操作！！！


***Chapter 7 压缩列表***   

   ziplist是列表键和哈希键的底层实现之一。
   其目的是redis为了节约内存而开发的， 是有一系列特殊编码的连续内存组成的顺序型（sequential）数据结构。

7.1 压缩列表构成
   * |zlbytes|zltail|zllen|entry1|entry2|...|entryN|zlend|
      * zlbytes：记录增个压缩列表占用的内存字节数
      * zltail：记录压缩列表尾节点距离压缩列表的其实地址有多少字节，程序可通过该变量快速定位尾节点
      * zllen：记录压缩列表包含的节点数量
      * entryX：压缩列表包含的各个几点，
      * zllen：一个字节，值为0XFF，用于标记压缩列表的末端

7.2 压缩列表节点的构成
   * |previous_entry_length|encoding|content|   
      * previous_entry_length : 一个字节或者五个字节
         * 长度小于254， 一个字节来存储
         * 长度大于等于254，5个字节来存储，0XFE + length
      * encoding：记录了数据类型及长度
         * 一字节、两字节或者五字节长
      * content：保存的是节点的值

7.3 连锁更新
   * 因为previous_entry_length 存在变长的问题，可能引起连锁的更新
      * 在添加或者删除的时候

***Chapter 8： 对象***      

8.0 
   * Redis 没有直接使用上面的数据结构来实现数据库，而是基于这些数据结构创建了一个对象系统，这个系统包括字符串对象、列表对象、集合对象和有序集合对象。
   使用对象的好处：
      * 判定一个命令是否可以执行
      * 针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率
   * redis对象实现了基于引用计数的内存回收机制 + 对象共享机制
   * redis对象带有访问时间记录信息，噶信息可以使用计算数据库键d额空转时长，在服务器用了maxmemory功能的情况下，空转时长较大的那些键可能会被服务器优先删除

8.1 对象的类型与编码
   * 新建键值对的时候，会创建键对象 + 值对象
   ```
   typedef struct redisObject {
      unsigned type:4; // 类型
      unsigned encoding:4; // 编码
      void *ptrl; // 执行底层实现数据结构的指针
      int refcount; // 引用计数
      unsigned lru:22; // 最后一次被访问的时间
      ...

   } robj;
   ```   
   * type
   
   对象|对象的type属性的值|type 命令的输出
   ----|-----------------|----------------
   字符串对象|REDIS_STRING|string
   列表对象|REDIS_LIST|list
   哈希对象|REDIS_HASH|hash
   集合对象|REDIS_SET|set
   有序集合对象|REDIS_ZSET|zset
    
   * 编码和底层实现
   
   编码常量|编码所对应的底层数据结构
   -------|---------------------
   REDIS_ENCODING_INT|long类型的整数
   REDIS_ENCODING_EMBSTR|embstr编码的简单动态字符串
   REDIS_ENCODING_RAW|简单动态字符串
   REDIS_ENCODING_HT|字典
   REDIS_ENCODING_LINKEDLIST|双端链表
   REDIS_ENCODING_ZIPLIST|压缩列表
   REDIS_ENCODING_INTSET|整数集 
   REDIS_ENCODING_SKIPLIST|跳跃表和字典

   类型|编码|对象|object encoding输出
   ---|----|---|-------------------
   REDIS_STRING|REDIS_ENCODING_INT|使用整型值实现的字符串对象|"int"
   REDIS_STRING|REDIS_ENCODING_EMBSTR|使用embstr编码的简单动态字符串实现的字符串对象|"embstr"
   REDIS_STRING|REDIS_ENCODING_RAW|使用简单动态字符串实现的字符串对象|"raw"
   REDIS_LIST|REDIS_ENCODING_ZIPLIST|使用压缩列表实现的列表对象|"ziplist"
   REDIS_LIST|REDIS_ENCODING_LINEDLIST|使用双端链表实现的列表对象|"linkedlist"
   REDIS_HASH|REDIS_ENCODING_ZIPLIST|使用压缩列表实现的哈希对象|"ziplist"
   REDIS_HASH|REDIS_ENCODING_HT|使用字典表实现的哈希对象|"hashtabel"
   REDIS_SET|REDIS_ENCODING_INTSET|使用整数集合实现的集合对象|"intset"
   REDIS_SET|REDIS_ENCODING_HT|使用字典实现的集合对象|"hashtable"
   REDIS_ZSET|REDIS_ENCODING_ZIPLIST|使用压缩列表实现的有序集合对象|"ziplilst"
   REDIS_ZSET|REDIS_ENCODING_SKIPLIST|使用跳跃表+字典表实现的有序集合对象|"skiplist"
 
8.2 字符串对象
   * 编码可以是 int、embstr（<=32字节）或者raw（>32字节）
   * 对于raw编码，会调用两次内存分配来分别创建redisObject和sdshdr
   * 对于embstr则会调用一次内存分配函数来分配一块连续的内存（redisObject|sdshdr）
   * 编码转换规则
      * int -> str, 则直接用raw
      * embstr 不可变，embstr -> raw

8.3 列表对象
   * 编码可以是ziplist或者linkedlist
   * 编码转化
      * 同时满足以下两个条件时，使用ziplist编码  （限定值是可以修改的）
         * 列表对象报错的所有字符串元素的长度都小于64字节
         * 列表对象保存的元素量小元素512

8.4 哈希对象
   * 哈希队形的编码可以是ziplist或者hashtable
   * 编码转换
      * 当哈希对象可以同时满足以下两个条件是，哈希对象使用ziplist编码 （数值可配置）
         1. 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
         1. 哈希对象保存的键值对数量小于512个

8.5 集合对象
   * 结合对象的编码可以是intset或者hashtable
   * 编码转换
      * 当结合对象可以同时满足以下两个条件时，对象使用intset编码：
         1. 集合对象保存的所有元素都是整数
         1. 节后对象保存的元素数量不超过512

8.6 有序结合对象
   * 有序结合的编码可以是ziplist或者skiplist
   * zset
   ```
   typedef struct zset {
       zskplist *zsl; // zrange, zrank
       dict *dict; // zscore
   } zset;
   ```
   * 编码的转换
      * 当有序集合对象可以同时满足以下两个条件时，对象使用ziplist编码 （具体的数字可以修改）
         1. 有序集合保存的元素数量小于128个
         1. 有序结合保存的所有元素成员的长度小于64字节

8.7 类型检查与命令多态
   * 类型检查的实现
   * 多态命令的实现

8.8 内存回收
   * redisObject： int refcount; // 引用计数

8.9 对象共享
   * redis会共享值为0到9999的字符串对象

8.10 对象的空转时长
   * lru:22 记录了对象的 最后一次被访问的时间 #object idletime 命令不会更新该时间
   * 空转时长 = 当前时间 - lru

### 第二部分：单机数据库的实现 ###

***第9张：数据库***

9.1 服务器中的数据库
   * redisServer
   ```
   typedef struct redisServer {
       redisDb *db;  // 数组，保存服务器中的所有数据库
       int dbnum;    // 服务器的数据库数量
   } redisServer;
   ```

9.2 切换数据库   
   * cmd： SELECT 0 # default is 0
   * redisClient中保存了目标数据库的信息
   ```
   typedef struct redisClient {
      redisDb *db; // 记录客户端当前在使用的数据库
   } redisClient;
   ```

9.3 数据库键空间
   * redisDb
   	```
   	typedef struct redisDb {
   	    dict *dict;
   	} redisDb;
   	```
   * 操作
      * 添加：SET
      * 删除：DEL
      * 更新：SET、HSET
      * 取值：GET、HGET
      * 其他：FLUSHDB
   * 读写键空间的维护
      * 读取一个键之后，会根据键是否存在来更新服务器的键空间命中次数（hit）和不命中次数（miss），可在info stats中查看
      * 读取一个键之后，会更新键的LRU时间，可以计算出键的空闲时间
      * 读取一个键的时候发现键已过期则先删除该键，然后执行后续操作
      * 如果有客户端使用watch命令监视了某个键，那么服务器在对键修改之后会将这个键标记为脏（dirty），从而让事务程序知道该键已经修改过
      * 服务器每次修改键之后，都会对脏（dirty）键计数器+1，该计数器会触发服务器的持久化以及复制操作
      * 如果服务器开启了数据控通知功能，那么在对键进行修改之后，服务器将按照配置发送相应的数据库通知。

9.4 设置键的生存时间和过期时间
   * 设置过期时间
      * EXPIRE <key> <ttl>
      * PEXPIRE <key> <ttl>
      * EXPIREAT <key> <timestamp>
      * PEXPIREAT <key> <timestamp>
   * 保存过期时间
      * redisDb中的过期字典，保存键的过期时间
      ```
      typedef struct redisDb {
         dict *expires; // map<string, long long>
      } redisDb;
      ```
   * 移除过期时间
      * PERSIST <key>； // 从redisDb.expireDB 中移除，如果有的话
   * 计算并返回剩余生存时间
   * 过期键的判定

9.5 过期键的删除
   * 常见的删除策略
      1. 定时删除：在设置建的过期时间是，创建一个timer，时间到的时候立即删除
      1. 惰性删除：放任键过期不管，但每次从键空间获取时，都检查键是否过期，如果过期就删除，没有过期则返回
      1. 定期删除：每个一段时间，程序就对数据库进行一次检查，删除里面的键。至于要删除多少键和检查多少数据库由算法决定。
   * 定时删除 
      * 是主动删除
      * 对内存友好，对CPU不友好
   * 惰性删除
      * 是被动删除
      * 对CPU友好，对内存不友好
      * 可能会有空间一直得不到释放
   * 定期删除
      * 是前面两者的整合和折中
         * 定期删除策略每个一段时间执行一次删除过期键操作，通过限制每次操作的时长和批量练减少删除操作对cpu时间的影响
         * 有效减少了内存浪费
      * 难点
         * 时长
         * 频率

9.6 redis的过期键删除策略
   * redis使用惰性删除和定期删除两种策略
   * expiredIfNeeded
   * 定期删除策略的实现
      * 策略：redis.c/activeExpireCycle函数实现
      * 每当服务周期性操作redis.c/serverCron函数执行时activeExpireCycle就会被调用

9.7  AOF、RDB和复制功能对过期键的处理
   * 生成RDB文件：SAVE、BGSAVE创建一个新的rdb文件， 过期键不会被写入
   * 载入RDB文件
      * 主从模式的主，载入rdb文件不会载入过期键
      * 主从模式的从，会载入过期键
   * AOF文件写入
      * 键删除之后会写入AOF文件
   * AOF重写
      * 已过期键不会写入
   * 复制
      * 当服务器运行在复制模式下时，从服务器的过期键删除动作由主服务器控制
         * 主服务器在删除一个过期键之后，会显示地向从服务器发送一个DEL命令
         * 从服务器在执行客户端发送的命令时，及时碰到过期键也不会删除，而是继续像处理未过期的键一样
         * 从服务器之后在接受到主服务器发来DEL命令之后，才会删除key

9.8 数据库通知
   * SUBSCRIBE __keyspace@0__:message
   * SUBSCRIBE __keyspace@0__:del


***第10章：RDB持久化***

10.1 RDB文件的创建和载入
   * SAVE 
      * 调用rdbSave()
      * 执行期间redis会被阻塞，客户端请求会被拒绝
   * BGSAVE
     * fork子进程来做
        * 子进程调用rdbSave()，然后signal_parent()
        * 父进程继续处理命令，并且通过轮询等待子进程信号
   * RDB文件载入时，服务器会一直阻塞

10.2 自动间隔性保存
    * 配置，任意满足则触发bgsave
    ```
    save 900 1
    save 300 10
    save 60 10000
    redisSever{
       struct saveparam * saveparams;// 记录了保存条件数组
       long long dirty; //修改计数器，距离上次成功执行save或者bgsave之后服务器对于数据库状态（服务器中的所有数据库）进行多少次修改
       time_t lastsave;// 上次成功执行save或者bgsave的时间
    }
    typedef struct saveparam {
       time_t seconds;
       int changes;
    } saveparam;
    ```
    * 检查保存条件是否满足
       * serverCront默认每个100ms就会执行一次，该函数用于对正在运行的服务器进行维护，其中一项就是检查条件是否满足，如果满足则进项bgsave

10.3 RDB文件结构
   * overall
    |REDIS|db_version|databases|EOF|checksum|
   * databases
    |SELECTDB|db_number|key_value_pairs|
   * key_value_pairs 
    |TYPE|key|value| 
    |EXPIRETIME_MS|ms|TYPE|key|value|
   * value 的编码
      * 字符串对象：|ENCODING|val|，有压缩和不压缩的差别
      * 列表对象 |list_length|item1|item2|...|itemN|
      * 集合对象：|set_size|elem1|elem2|...|elemN|
      * 哈希表对象：|hash_size|key_value_pair1 |key_value_pair2|...|keyvalue_pairN|
      * 有序集合对象：|sorted_set_size|elemtn1|elemtnt2|...|elementN|
      * intset编码的集合：整数集合字符串化
      * ziplist编码的列表、哈希表或者有序结合
         * 将压缩列表转换成一个字符串对象

10.4 分析RDB文件
   * od -cx dump.rdb

***Chapter 11: AOF持久化***

11.1 AOF （Append Only File）持久化的实现   
   * 命令追加
      * 执行写命令之后会以协议格式将被执行的命令追加到服务器的aof_buf缓存区的末尾
   ```
   struct redisServer {
       sds aof_buf; // AOF缓冲区
   };
   ```
   * AOF问价的写入与同步
   ```
   def eventLoop():
      while Ture:
         # 处理文件事件、接受命令请求以及发送命令回复
         # 处理命令请求时可能有新内容被最爱到aof_buf缓冲区中
         processFileEvents()

         # 处理事件事件
         processTimeEvents()

         # 考虑是否要将aof_buf中内容写入和保存到AOF文件里面
         flushAppendOnlyFile()
   ```
   * appendfsync 选项
      * always: 将aof_buf缓冲区中的所有内容写入并同步到AOF文件
      * everysec：将aof_buf缓冲区中的所有内容写入到AOF问价，如果上次同步AOF文件的时间鞠距离现在超过一秒钟，那么再次对AOF文件进行同步，并且这个同步由一个线程专门负责执行
      * no：将aof_buf缓冲区的所有内容写入AOF文件，但是何时同步将由操作系统同步
   * 文件的写入与同步
      * 现在OS中write()函数仅将内容写入缓冲区，等到缓冲区被填满或者超过指定的时限之后，才能将缓冲区中的内容写入磁盘
      * 有fsync和fdatassyanc两个同步函数，来强制系统将缓冲区中的内容写入磁盘

11.2 AOF文件的载入与数据还原
   * 载入步骤：
      1. 创建一个不带网络连接的伪客户端
      1. 从aof文件中分析并读取一条命令
      1. 使用为客户端执行被读出的写命令
      1. 重复前两个步骤直到处理完成

11.3 AOF重写
   * aof_rewrite : 阻塞，导致无法处理客户端需求
   * aof 后台重写
      * 为了保证一致性，重写期间服务器进程
         1. 执行客户端发来的命令
         2. 将执行后的命令追加到AOF缓冲区 （确保现有的aof正确）
         3. 将执行后的命令追加到AOF重写缓冲区（确保未来的aof正确）

***Chapter 12：事件***

   Redis服务器是一个事件驱动程序，主要处理两类事件
   * 文件事件（file event）
   * 时间事件（time event）
      * 比如serverCron

12.1 文件事件
   * 基于Reactor模式开发了自己的网络事件处理器，（file event handler）
      * 文件事件处理器使用I/O多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器
      * 当被监听的套接字准备好连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相关联的文件事件就会产生，这是文件事件处理器就会调用套接字之前关联好的事件处理器来处理
   * 文件事件初期器的构成
      1. 套接字
      1. I/O多路复用程序
         * 将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序（sequentially）、同步（Synchronously）、每次一个套接字的方式向文件事件分配器传送
         * 当上一个套接字产生的时间呗处理完毕之后，I/O多路复用程序才会向文件事件分派器传送下一个套接字
      1. 文件事件分派器（dispatcher）
      1. 事件处理器
   * I/O多路复用程序的实现
      * select、epool、evport和kqueue
   * 事件的类型
      * AE_READABLE (优先处理)
      * AE_WRITEABLE
   * API
      * ae.c/aeXXXFileEvent
   * 文件事件处理器
      1. 连接应答处理器：networking.c/accetpTcpHandler：客户端connect时候
      1. 命令请求处理器：networking.c/readQueryFromClient
         * 在客户端链接服务器过程中，服务器会一直为客户端套接字的AE_READABLE事件关联命令处理器
      1. 命令回复处理器：networking.c/sendReplyToClient
         * 当服务器有命令回复需要传送给客户端时候，服务器会将客户端的AE_WRITEABLE事件和命令回复处理器关联起来；发送完毕之后服务器会接触该关联
      1. 一次完整的客户端与服务器连接事件示例

12.2 时间事件
   * 事件类型
      * 定时事件
      * 周期性事件
   * 时间事件的三个属性
      1. id：全局唯一ID，新的比旧的大
      1. when：毫秒精度的unix时间戳，记录事件的到达时间
      1. timeProc：时间事件处理器
   * 事件类型的判定
      * 如果事件处理器返回ae.h/AE_NOMORE，则为定时事件，事件到达之后会被删除，之后不会再到达
      * 如果返回一个非AE——NOMORE，则是一个周期性时间
   * time_events in redisServer
   * 实例：serverCron函数
      * 更新服务器的各类统计信息，比如时间、内存占用、数据库占用等
      * 清理数据库中的过期键值对
      * 关闭和清理链接失效的客户端
      * 尝试进行AOF或RDB的持久化
      * 如果服务器是主服务器，那么对从服务器进行定期同步
      * 如果处于集群模式，对集群进行定期同步和链接测试

12.3 事件的调度与执行
   * 时间的调度和执行由ae.c/aeProcessEvents函数负责
   ```
   def aeProcessEvents():
      # 获取到达时间离当前时间最接近的时间事件
      time_event = aeSearchNearestTimer()
     
      # 计算最接近的时间事件距离到达时间还有多少毫秒
      remaind_ms = time_event.when - unix_ts_now()

      # 如果事件已经到达，那么remaind_ms的值可能为负，设置为0
      if remaind_ms < 0:
          remaind_ms = 0

      # 根据remaind_ms的值，创建timeval结构
      timeval = create_timeval_with_ms(remaind_ms)

      # 阻塞并等待文件事件产生，最大阻塞时间由传入的timeval结构决定
      # 如果remaind_ms的值为0，那么aeApiPoll调用马上返回，不阻塞
      aeApiPool(timeval)

      # 处理已经产生的文件事件
      processFileEvents()

      # 处理所有已达到的时间事件
      processTimeEvents()
   ```
   * redis服务器的主函数
   ```
   def main():
       # 初始化服务器
       init_server()

       # 一直处理事件，知道服务器关闭为止
       while server_is_not_shutdown():
           aeProcessEvents()

       # 服务器关闭，执行清空操作
       clean_server()

   ```

***Chapter 13: 客户端***

   * redisServer中有一个 clients列表

13.1 客户端属性
   * 分为两类
      1. 通用属性，这些属性很少与特定的功能相关，无论客户端执行什么工作，他们都要用到这些属性
      1. 另一类是和特定功能相关的属性，比如操作数据库是需要用到的db属性和dict-id属性，执行事物时用到的mstate属性，以及WATCH命令用到的watched_keys属性
   * 套接字属性
      1. int fd; // 套接字
         * 伪客户端（faked client）的值为-1
         * 普通客户端，值为大于-1的整数
      1. robj* name; // 名字
      1. int flags;// 标志
         * 记录了客户端的角色（role），以及客户端目前所处的状态
      1. sds querybufer; // 输入缓冲区   
         * 缓存客户端发来的命令
      1. robj ** argv; // 参数列表
      1. int argc; // 参数长度
      1. struct redisCommand *cmd; // 命令的实现函数
         * redis中存在一个命令字典
         * 根据argv[0] 查询
      1. char buf[REDIS_REPLY_CHUNK_BYTES];
      1. int bufpos;
      1. list *reply; // 可变大小缓冲区
      1. int authenticated; // 身份验证
      1. 时间相关
         * time_t ctime;
         * time_t lastinteraction;
         * time_t obuf_soft_limit-reached_time;//  记录了输出换从去第一次到达软性限制的时间

13.2 客户端的创建与关闭
   * 创建普通客户端
      * 置于clients列表
   * 关闭普通客户端
      * 客户端进程退出、client kill、服务端timeout设置、客户端发送的命令请求的大小超过输入缓冲区大小（1GB）、要发给客户端的命令回复的大小超过了输出缓冲区的限制大小
      * 服务器使用两种模式来限制客户端输出缓冲区的大小
         * 硬性限制
         * 软性限制：obuf_soft_limit_reached_time
   * lua脚本的伪客户端
      * redisClient *lua_client; // 生命周期中一直存在
   * AOF文件的为客户端
      * 服务器在载入AOF文件时，会创建一个为客户端，用后关闭


***Chapter 14：服务器***

14.1 命令请求的执行过程 ： SET KEY VALUE
   * 过程：
      1. 客户端想服务器发送命令请求 SET KEY VALUE
      1. 服务器接收到并处理客户端发来的命令请求，在数据库中进行设置，并产生命令回复OK
      1. 服务器将命令回复OK发送给客户端
      1. 客户端接收到服务器返回来的命令回复OK，并将这个回复打印给用户看
   * 发送命令请求：客户端将命令转换成协议
   * 读取命令请求
      * 从socket读取命令，保存到保存客户端的输入缓冲区里面
      * 对缓冲区内容进行分析，提取参数
      * 调用命令执行器，执行客户端指定的命令
   * 命令执行器：查找命令实现
      * 根据argv[0] 到命令表中查找指定的命令，并且保存到客户端的cmd属性中
      * redisCommand结构的主要特性
      
      属性名|类型|作用
      -----|----|-----
      name|char *|命令的名字， 如set
      proc|redisCommandProd *|执行命令的实现函数的函数指针
      arity|int|命令的参数个数，如果是负数(-N)，则标识个数>=N
      sflags|char *|记录了命令的属性：读、写、是否允许
      flags|int|碎玉sflags分析得出的二进制标识
      calls|long long|服务器执行该命令的总次数
      milliseconds|long long|服务器执行该命令所耗费的时长
      
   * 命令执行器：执行预备操作
      * 检查客户端状态的cmd指针是否指向NULL，如果为空，这返回
      * 根据cmd属性指向的redisCommand结构的arity属性，检查命令行参数的个数，不符合则返回
      * 检查客户端是否通过了身份验证
      * 如果服务器打开了maxmemory功能，则在执行命令前，先检查服务器内存占用情况，并在有需要时进行内存回收
      * ...
   * 命令执行器：调用命令的实现函数
      * client->cmd->proc(client)
      * 回复会保存在buf和reply属性
      * 为客户端套接字关联 命令回复处理器
   * 命令执行器：执行后续工作
      * 如果开启了慢查询功能，则添加一条新的慢查询日志
      * 根据执行时长，更新执行命令的redisCommand结构的milliseconds属性，并将命令的redisCommand结构的calls计数器增1
      * 如果开启AOF持久化，则将命令加入到AOF缓冲区
      * 如果其他从服务器正在复制当前这个服务器，那么服务器就会将刚才执行的命令传播给所有的从服务器
   * 将命令回复发送给客户端
      * 客户端接受并打印命令回复

14.2 serverCron函数
   *  默认100ms执行一次，负责管理服务器的资源，并且保持服务器自身的良好运转
   * 更新服务器时间缓存
   ```
   struct redisServer {
       time_t unixtime;//保存了秒级精度的系统当前UNIX时间戳
       long long mstime;//保存了毫秒级进度的系统当前UNIX时间戳
       unsigned lruclock:22; 默认10s更新一次的时钟缓存，用于计算键的空转时间
   }
   ```       
      * 时间进度孤高，默认100ms才更新一次
      * 服务器知会打印日志、更新服务器LRU时钟、决定是否执行持久化任务、
   * 更新LRU时钟 ： redisServer.lruclock - redisObject.lru  
   ```
   typedef struct redisObject {
      unsinged lru:22; // 保存对象最后一次被命令访问的时间
   }
   ```
   * 更新服务器每秒执行的命令数
      * serverCron()->trackOperationsPerScond()
   ```
   struct redisServer {
      //上次抽样的时间
      long long ops_sec_last_sample_time;
      //上次抽样时，服务器已执行的命令的数量
      long long ops_sec_last_sample_ops;
      // REDIS_OPS_SEC_SAMPLES大小（默认为16）的环形数组，数组中每个项都记录了一次抽样结果
      long long ops_sec_samples[REDIS_OPS_SEC_SAMPLES];
      //ops_sec_samples数组的索引值，每次抽样周将值自增1，在等于16时重置为0，
      int opos_sec_idx;
   };
   ```
   * 更新服务器内存峰值记录
      size_t stack_peak_memory; // 已使用内存峰值
   * 处理SIGTERM信号
      * 服务启动时，redis会为服务器进程的SIGTERM信号管理处理器sigtermHandler函数，当该信号达到服务器时，打开服务器状态的shutdown_asap标识
      int redisServer.shutdown_asap;// 1 关闭，0 不做动作
   * 管理客户端资源
      * serverCron函数每次执行都会调用clientsCron函数，clientsCron会执行以下检查
         1. 如果连接已经超时，则释放该客户端
         1. 如果客户端在上一次执行命令请求之后，输入缓冲区的大小超过了一定的长度，那么程序会释放客户端当前的输入缓冲区，并重新创建一个默认大小的输入缓冲区
   * 管理数据库资源
      * 调用databaseesCron函数，会对服务器中的一部分数据库进行检查，删除其中的过期键，并在有需要时，对自检进行收缩操作
   * 执行被延迟的BGREWTIREAOF
      * int aof_rewrite_scheduled;// 如果值为1，表示有BGREWRITEAOF命令被延迟了
   * 检查持久化操作的运行状态
      * pid_t rdb_child_pid; // BGSAVE 命令执行期间的子进程ID
      * pid_t aof_child_pid;//执行BGREWRITEAOF命令的子进程ID
      * 检查两个属性的值，如果有一个不为-1，就执行wait3操作，检查是否有子进程发来信号
         * 如果有信号，替换相应的文件
         * 如果没有，则啥也不干
      * 如果都为-1
         1. 检查AOF是否被延迟了，若有，则开始
         1. 检查服务器的自动保存条件是否已经满足，如果满足，并且执行服务器没有执行其他持化操作，则服务器进行BGSAVE
         1. 检查服务器设置的AOF重写条件是否满足
   * 将AOF缓冲区中的内容写入AOF文件
   * 关不异步客户端
   * 增加cronloops计数器，记录serverCron函数执行的次数
      * 目前该值的应用是运行N次就执行一次指定的代码

14.3 初始化服务器
   1. 初始化服务器状态结构      
      * initServerconfig(void)//负责属性
   1. 载入配置选项
   1. 初始化服务器数据结构
      * initServer（）
         * 负责初始化数据结构
            * server.clents
            * server.db
            * server.pubsub_patterns
            * server.lua
            * server.slowlog
         * 重要设置
            * 为服务器设置进程信号处理器
            * 创建共享对象：OK、ERR、1~10000字符串对象
            * 打开服务器的监听端口，关联应答时间处理器
            * 为serverCron时间事件
            * 打开AOF持久化，如果配置了的话
            * 初始化服务器的后台I/O模块（bio）为将来的I/O操作准备好
   1. 还原数据库状态
      * AOF or RDB
   1. 执行事件循环 loop


***Chapter 15：复制***

   * SLAVEOF 或者设置 slaveof选项

15.1 旧版本（2.8之前）复制功能的实现
   * 分为同步（sync）和命令传播（command propagate）两个操作
      * 同步用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态
      * 命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，让主从服务器数据库重新回到一致状态。
   * 同步
      * 客户端性从服务器发送SLAVEOF命令，妖气从服务器复制主服务器时，从服务器首先需要执行同步操作
         1. 从服务器想主服务器发送SYNC命令
         1. 收到SYNC命令的主服务器执行BGSAVE命令，在后台生成一个RDB文件，并用一个缓冲区从现在开始记录执行的所有写命令
         1. 当主服务器的BGSAVE命令执行完毕时，主服务器会将BGSAVE命令生成的RDB发送给从服务器，从服务器接受并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令是的数据库状态
         1. 主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。
   * 命令传播
      * 主服务器会将自己执行的写命令，也即是造成蛀虫服务器不一致的那条写命令，发送给从服务器执行。

15.2 旧版本复制功能的缺陷
   * 在从服务器断开之后，重新连接上并复制的场景，需要全量复制，效率较低。 

15.3 新版复制功能的实现
   * 新版的PSYNC命令代替SYNC命令，具有完成重同步和部分重同步的两种模式
      * 完成重同步，用于处理初次发复制的情况：完整重同步的执行步骤和SYNC命令一样。
      * 部分重同步则用于处理断线后重复值的情况：当从服务器在断线后重新连接主服务器时，如果条件运行，主服务器可以将主从服务器连接断开期间执行的写命令发送给同步服务器，从服务器只需要执行自威胁写命令，就可以将数据库更新至主服务器的状态。

15.4 部分重同步的实现
   * 有三个部分构成:
      1. 主服务器的复制偏移量（replication offset）和从服务器的肤质偏移量
      1. 主服务器的复制积压缓冲区（replicationbacklog）
      1. 服务器的运行ID（run ID）
   * 复制偏移量
      * offset
   * 复制积压缓冲区
      * 是有主服务器维护的一个固定长度（fixed-size）的先进先出（FIFO）队列，默认大小是1MB
      * 当主服务器进行命令传播时，他不仅会将写命令发送给所有的从服务器，还会降写命令入队到复制积压缓冲区里面
      * 默认大小是1MB
      * PSYNC（+从自己的偏移量offset）发送之后
         * 如果主上offset之后的数据任然在复制积压缓冲区，则主服务器对从服务器进行部分重同步操作
         * 星饭，如果offest偏移量之后的数据已经不再复制积压缓冲区，那么主服务器对从服务器执行完整同步操作
   * 服务器运行ID
      * 每个redis服务器，不论主从，都会有自己的运行ID
      * 运行ID在服务器启动时自动生成，40个随机的16进制字符组成

15.5 PSYNC命令的实现
   * PSYNC 命令的调用方法
      * 如果从服务器之前没有父之过任何主服务器，或者至前执行过SLAVEOF no one命令，那么从服务器在开始一次新的复制是想主服务器发送PSYNC ? -1 命令主动请求主服务器进行完整重同步（因为这个是不可能执行部分重同步）
      * 相反，如果从服务器已经父之过某个主服务器，那么从服务器在开始一次新的复制时想主服务器发送PSYNC <runid:上一次复制的主服务器的运行id> <offset：当前服务器的偏移量>
   * 接受到PSYNC命令的主服务器一般会有以下三种回复
      * 主服务器返回 +FULLRESYNC <runid> <offset>
      * 主服务器返回 +CONTINUE：表示主服务器将与从服务器执行部分同步
      * 主服务器返回-ERR回复，那么表示主服务器版本低于Redis 2.8，其识别不了PSYNC命令

15.6 复制的实现
   * 通过向从服务器发送 SLAVEOF <master_ip> <master_port>
   * 步骤1：设置主服务器的地址和端口
   ```
   struct redisServer {
      char *masterhost;
      int masterport;
   }
   ```
   * 步骤2：简历套接字连接
   * 步骤3：发送PING命令
      * 发送ping命令可以检查套接字的读写状态是否正常
      * 检查主服务器是否能处理PING命令
         * 如果主返回PONG，则执行下一步
         * 如果超时或者主服务器返回错误，则断开套接字
   * 步骤4：身份验证
   * 步骤5：发送端口信息
      * 从执行：REPLCONF listening-port <port_number>，向主服务器发送从服务器的监听端口号
   ```
   typedef struct redisClient {
       int slave_listening_port;
   }
   ```
   * 步骤6：同步
   * 步骤7：命令传播

15.7 心跳检测
   * 在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送命令 ： REPLCONF ACK <replication_offset>
      * 检测主从服务器的网络连接状态
      * 辅助实现min-slave选项
      * 检测命令丢失
   * 检测主从服务器的网络连接状态
   * 辅助实现min-slaves配置选项
      * min-slaves-to-write 3
      * min-slaves-max-lag 10
   * 检测命令丢失
      * 如果检测到会重新发送执行命令


***Chapter 16：Sentinel***

16.1 启动并初始化Sentinel
   * 命令：resis-sentinel /path/ot/your/sentinel.conf || redis-server /path/to/your/sentinel.conf --sentinel
   * 启动时步骤
       * 初始化服务器
       * 将普通redis服务器使用的代码替换成Sentinel专用代码
       * 初始化sentinel状态
       * 根据给定的配置文件，初始化Sentinel的监视的主服务器列表
       * 创建连想主服务器的网络连接
   * 初始化服务器
   * 使用sentinel专用代码
      * 替换commandTable
   * 初始化Sentinel状态
   ```
   struct sentinelState {
      // 当前纪元，用户实现故障转移
      uint64_t current_epoch;
      // 保存了所有被这个Sentinel简史的主服务器
      // 字典的键是主服务器的名字
      // 字典的值择时一个指向sentinelReisInstance结构的指针
      dict *masters;
      // 是否进入了TILT模式
      int tilt;
      // 目前正在执行的脚本的数量
      int running_scripts;
      // 今日TILT模式的时间
      mstime_t tilt_start_time;
      // 最后一次执行时间处理器的时间
      mstime_t previous_time;
      // 一个FIFO队列，包含了所有需要执行的用户脚本
      list *scripts_queue;
   };
   ```
   * 初始化Sentinel状态的master属性
   ```
   type struct sentinelRedisInstance {
      // 标记值，记录了实例的类型，一斤该实例当前的状态
      int flags;
      // 实例的名字，主服务器的名字有用户在配置文件中的设置，从服务器以及sentinel的名字有sentinel自动设置
      char *name;
      // 实例的运行id
      char *runid;
      // 配置纪元，用于实现故障转移
      uint64_t config_epoch;
      // 实例地址
      sentinelAddr *addr;
      // sentential down-after-milliseconds 选项设定的值
      //实例无硬性多好毫秒之后才会被判定为主观下线
      mstime_t down_after-period;
      // sentinel monitor <mater-name> <ip> <port> <quorum> 选项中的quorum参数，判断这个实例为下线所需的支持投票数量
      int quorum;

      // sentinel parallel-syncs <master-name> <number> 选项的值，在执行故障转移操作时，可以同时对新的主服务器进行同步的从服务器数量
      int parallel_syncs;

      // sentinel failover-timeout <master-name> <ms> 选项的值，刷新故障迁移状态的最大时限
      mstime_t failover_timeout;

   }sentinelRedisInstance;
   typedef struct sentinelAddr {
      char *ip;
      int port;
   } sentinelAddr;

   ```
   * 创建联想主服务器的网络连接
      * 对于每个被sentinel简史的主服务器来说，sentinel会创建两个联想主服务器的异步网络连接：
         1. 一个是命令连接，这个链接转么用于向主服务器发送命令，并接受命令回复
         1. 另一个是订阅链接，这个链接转么用于订阅主服务器的__sentinel__:hello频道

16.2 获取主服务器信息
   * sentinel默认会以没事秒一次的频率，通过命令连接想被监视的主服务器发送INOF命令，并通过分析INFO命令的回复来获取主服务器的当前信息
   * 可以获取主的信息 + 从的信息

16.3 获取从服务器信息
   * 当sentinel发主服务器有新的从服务器出现时，sentinel除了会为这个心的从服务器创建相应的实例结构之外，Sentinel还会创建连接到从服务器的命令连接和订阅连接
   * 发送INFO命令

16.4 向主服务器和从服务器发送信息
   * 通过命令连接发送命令 PUSBLISH __sentinel__:hello "<>,<>...."   
   * sentinel 通过命令连加发送信息到频道

16.5 接受来自主服务器和从服务器的频道信息
   * sentinel订阅服务器的__sentinel__:hello 频道
      * sentinel接收到信息的后会parse该信息，可能是自己发的则丢弃，也可能是其他sentinel发送的，则用来更新相应的信息
   * 更新sentinels字典
      * 监视同一个主服务器的多个sentinel可以自动发先其他的sentinel
   * 创建链向其他sentinel的命令连接
      * 最终监视同一主机的多个sentinel将形成相互连接的网络。

16.6 检测主观下线状态
   * 默认情况下sentinel会每秒一次的频率想所有与他创建命令连接的实例（包括主服务器、从服务器、其他sentinel在内）发送PING命令，并通过历史返回的PING命令回复来判断实例是否在线。
   * 根据回复内容来判定主服务器是否下线
      * 在down-fater-milliseconds毫秒内，连续向sentinel返回无效回复。

16.7 检查客观下线状态
   * 当sentinel将一个主服务器判定为主观下线之后，为了群人这个主服务器是否真的下线了   ，他会想同样监视这一主服务器的其他sentinel进行询问，看他们是否也认为这个主服务器下线（可以是主观或是客观）。当sentinel从其他sentinel哪里接收到足够数量的已下线判断之后，sentinel就会将服务器判定为客观下线，并对主服务器执行故障转移
   * 发送sentinel is-master-down-by-addr <ip> <port> <current_epoch> <runid>以询问其他sentinel是否同意主服务器已下线。
   * 接收sentinel is-master-down-by-addr 
      * 统计其他sentinel统一服务器下线的数量，当这一数量达到配置置顶的判断客观下线所需的数量时，Sentinel会将主服务器实力结构flags属性的SRI_O_DOWN标识打开，标识已经进入客观下线。 

16.8 选举领头Sentinel： RAFT算法
   * 当主服务器被判断客观下线时，简史这个显现主服务器的各个sentinel会进行协商，选举出一个领头Sentinel，并有领头Sentinel对显现主服务器执行故障转移操作
   * 选择领头Sentinel的规则和方法：
      1. 所有在线的sentinel都有被选为领头sentinel的资格
      1. 每次进行领头Sentinel选举之后，不论选举是否成功，所有sentinel配置纪元（configuration epoch）的值都会自增一次。
      1. 在一个配置纪元里面，所所有的sentinel都有一次将某个sentinel设置为局部领头sentinel的机会，并且局部领头一旦设置，在这个配置纪元里面就不能再更改
      1. 每个发现主服务器客观下线的sentinel都会要求其他sentinel将自己设置为局部领头sentinel
      1. 当一个sentinel（源）想另一个sentinel（目标）发送sentinel is-master-down-by-addr命令，并且命令中的runid参数不是 * 符号而是源sentinel的运行ID时，这表示源sentinel要求目标sentinel将前者设置为后者的局部领头sentinel
      1. sentinel设置局部领头sentinel的规则是先到先得
      1. 目标sentinel在接收到sentinel is-master-down-by-addr 命令之后，将向源sentinel发挥一条命令回复，恢复中的leader_runid参数和leader_epoch参数分别记录了目标sentianle的局部领头sentinel的运行id和配置纪元
      1. 源sentinel在接收到目标sentinel返回的命令回复之后，会检查恢复中leader_epoch参数的值和自己的配置纪元是否相同，如果相同，则源sentinel继续去除回复中的leader_runid参数，如果leader_runid参数的值和源sentinel的运行id一直，则标识目标sentinel奖源sentinel设置为了局部领头sentinel
      1. 如果有某个sentinel被半数以上的sentinel设置为了领头sentinel，那么该sentinel成为领头sentinel。
      1. 如果给定时间内，每个有一个sentinel被选举为领头sentinel，那么各个sentinel将在一段时间之后再次进行选举，知道选出领头sentinel为止

16.9 故障转移
   * 三步骤：由领头sentinel操作
      1. 在已经下线的主服务器的所有从服务器里面，挑选出一个从服务器，并将其设置为主服务器
         * 按照一定规则选出之后，对选中服务器发送 SLAVEOF no one
      1. 让已下线主服务器属下所有从服务器修改复制新的主服务器
         * 发送SLAVEOF <ip> <port>
      1. 将已下线主服务器设置为新的主服务器的从服务器，当这个旧的从服务器重新连上时，他就会成为新的主服务器的从服务器
         * 重新上线时会发送 SLAVEOF 命令



***Chapter 17. 集群***

17.1 节点
   * 通过 CLATER MEET <ip> <port> 命令连接
      * 向一个节点发送cluster meet命令， 可以让node节点与目标ip和port所指定的节点进行握手，成功之后，node节点就会将ip和port指定的节点添加到node节点当前所在的急群中
   * 启动节点
      * cluster-enabled
        * true：集群模式
        * false：standalone模式
      * serverCron会调用clusterCron函数
         * 发送Gossip消息，检查是否断线，或者进行故障转移
   * 集群数据结构
   ```
   struct clusterNode {
      // 创建节点的时间
      mstime_t ctime;
      // 节点名字，40个十六进制字符组成
      char name[REDIS_CLUSTER_NAMELEN];
      // 节点表示：角色 + 状态
      int flags;
      // 节点当前纪元，用于实现故障转移
      uint64_t configEpoch;
      // 节点的ip
      char ip[REDIS_IP_STR_LEN];
      // 节点端口
      int port;
      // 保存链节点所需的有关信息
      clusterLink *link;
   }；
   typedef struct clusterLink {
      mstime_t ctime;// 链接创建时间
      int fd; //tcp套接字描述符
      sds sndbuf; // 输出缓冲区
      sds rcvbuf; // 输入缓冲区
      struct clusterNode *node;// 与这个连接相关联的节点
   } clusterLink;
   typedef struct clusterState {
      clusterNode *myself; // 指向当前节点的指针
      uint64_t currentEpoch;// 集群当前的配置纪元，用于实现故障转移
      int state;//集群当前的状态
      int size;//急群众至少处理着一个槽的节点的数量
      dict *nodes;// 集群中所有的节点
   }
   ```
   * CLUSTER MEET命令的实现
      * A MEET---> B
      * A <---(pong) B
      * A PING---> B

17.2 槽指派
   * redis 集群通过分片的方式来保存数据库中的键值对：集群被划分为16384个slot
      * 16384 = 2 ** 14
      * 每个节点可处理0~16384个槽
      * 当数据库中16384个槽都有节点在处理时，汲取处于OK，否则处于fail
      * cluster addslots
   * 记录节点的槽指派信息
   ```
   struct clusterNode {
      unsinged char slots[2 ** 14/8];// 位数组
      int numslots;
   };
   ```
   * 传播节点的槽指派信息
      * 节点将自己的槽指派信息传递给集群中其他的节点
      * 这些信息会存在其他节点的clusterState.nodes.get(name).slots数组中
      * 集群中每个节点都有全局视角
   * 记录集群中所有槽的纸片信息
   ```
   struct clusterState {
      clusterNode *slots[2**14];
   };
   * CLUSTER ADDSLOTS <slot> [slot ...]
   ```
   ```
   def CLUSTER_ADDSLOTS(*all_input_slots):
      # 便利所有输入槽，检查是否都未被指派，如果有被指派，则返回错误，并终止
      for i in all_input:slots:
         if clusterState.slots[i] != NULL:
            reploy_error
            return
      # 如果输入合法，再次遍历
      for i in all_input_slots:
         clusterState.slots[i] = clusterState.myself;
         setSlotBit(clusterState.myself.slots, i)
   ```

17.3 在集群中执行命令
   * 当16384个槽都被指派之后，集群处于上线状态
   * 客户端想节点发送与数据库键有关的命令时，接收命令的节点会计算出要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己：
      * 如果是，直接处理
      * 若否，返回 MOVED错误，指引客户端专项到正确的节点
   * 计算键属于哪个槽
      * CRC16(key) & 16383
   * 判断槽是否由当前节点负责处理
      * clusterState.slots[i] 
   * moved 错误
      * MOVED <SLOT> <IP>:<PORT>
   * 节点数据库的实现
      * 键值对以及键值对的过期方式与standalone模式完全相同
      * 节点还会用clusterState.slots_to_keys跳跃表保存槽和键职期间的关系

17.4 重新分片
   * 实现原理
      * 由redis-trib负责执行
      * redis-trib对集群的单个超slot进行重新分片的步骤如下
         1. redis-trib 对目标节点发送 CLUSTER SETSLOT <slot> IMPORTING> <source_id>
         1. redi-trib对源节点发送CLUSTER SETSLOT <slot> MIGRATING <target_id>
         1. redis-trib 向源节点发送CLUSTER GETKEYSINSLOT <slot> <count>命令，获取最多count个属于槽slot的键值对的键名
         1. 对于步骤3获得的每个键名，redis-trib都向源节点发送一个MIGRATE <target_ip> <target_port> <keyname> 0 <timeout> 命令，将键从源迁移至目标节点
         1. 重复3&4，直到所有节点迁移完成
         1. redis-trib 想集群中的任意一个节点发送CLUSTER SETSLOT <SLOT> <TARGET_ID> 命令，经槽slot指派给目标节点，这一指派信息会通过消息发送给整个集群，最终集群中的所有节点都会知道slot已经指派给了目标节点

17.5 ASK 错误
   * 在重新分片期间，源节点想目标节点迁移一个槽的过程中，可能会出现这样一种情况，属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对保存在目标节点里面
      * 如果要处理的键属于正在迁移的槽
         1. 源节点会现在自己的数据库里面查找置顶的键，如果找到的话，就直接执行命令
         1. 若相反，则该键有可能已经被迁移到新的节点，源节点想客户端返回一个ASK错误，置顶客户端转向正在导入槽的目标节点，并在此发送之前想要执行的命令
   * cluster setslot importing命令实现: clusterState中
      * clusterNode *importing_slots_from[16384];
      * 值不为NULL，则标识正在导入
   * CLUSTER SETSLOT migrating 命令的实现：clusterState中
      * clusterNode *migrating_slots_to[16384];
   * ASK错误
      * 如果节点不在自己的数据库中，那么会检查clusterState.mirgrating_slots_to[i]，查看key所属的槽i是否正在迁移，如果是则发送一个ASK错误
   * ASKING命令
      * 打开该命令客户端的REDIS_ASKING标识
      * REDIS_ASKING是一个一次性的标识
   * ASK与MOVED的区别
      * moved标识槽的负责权已经从一个节点转移到另一个节点
      * ask错误只是两个节点在迁移槽的搓成中使用的一种临时措施

17.6 复制与故障转移
   * 设置从节点
      * CLUSTER REPLICATE <node_id>
         * 让接受命令的节点成为nodeid的从节点
         * 相当于slaveof命令
         ```
         struct clusterNode {
            //从
            struct clusterNode *slaveof; // 是谁的slave
            //主
            int numslaves;
            struct clusterNode **slaves;
            //记录了其他节点对该节点的下线报告
            list  *fail_reports;
         };
         ```
         * 这个信息slave信息也是会同步给集群中其他的节点===>集群中每个节点还是有全局事视野的
   * 故障检测
      * 集群中的每个节点都会定期地向集群中的其他节点发送PING命令
         * 若果未收到pong消息，会将接受ping消息的节点标志位疑似fail
      * 集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点状态信息，
      ```
      struct clusterNodeFailReport {
         struct clusterNode *node;
         mstime_t time;
      };
      ```
      * 如果一个集群里面，半数以上负责处理槽的主节点都将某个x标记为疑似下线，那么这个主节点x将被标记为以下线（FAIL），将主节点x标记为已下线的节点会向集群广播一条关于主节点x的fail消息，所有收到这条fail消息的节点都会讲x标记为已下线
   * 故障转移：由从节点发起
      1. 复制下线主节点的所有从节点里面，会有一个从节点被复制
      1. 被选中的送节点会执行saveof no one命令，成为新的主节点
      1. 新的主节点会侧小所有对已下线主节点的槽指派，并将这些槽指派给自己
      1. 新的主节点想集区广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经有从节点编程主节点，并且这个主节点已经接管了原本有下线节点负责处理的槽
      1. 新的主节点开始接受和自己负责处理的槽有关的命令请求，故障转移完成
   * 选举新的主节点：基于Raft算法的领头选举（leader election）方法
      1. 集群的配置纪元是一个自增计数器，它的初始值是0
      1. 当集群里的某个节点开始一次故障转移操作时，集群配置纪元的值会被增1 
      1. 对于每个配置纪元，集群里每个负责处理槽的主节点都有一次投票的机会，而这个想主节点要求投票的从节点将获得主节点的投票
      1. 当从节点发现自己正在复制的主节点进入一下线状态时，从节点会广播CLUSTERMST_TYPE_FAILOVER_AUTH_REQUEST消息，要求所有接收到的、并具有投票权的主节点向这个从节点投票
      1. 如果一个主节点具有投票权（有处理的槽），并且这个主节点尚未投票给其他的从节点，那么主节点将向要求投票的从节点返回一条clustermsg_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点
      1. 每个参与选举的从节点都会收到CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种信息来统计自己获得多少的主节点的支持
      1. 如果集群里有N个具有投票权的主节点，那么当一个从节点收到大于N/2 +1 张支持票时，这个从节点就会当选为新的主节点
      1. 因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次，这点可以确保主节点只会有一个
      1. 如果再一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并在此进行选举，知道选出新的主节点为止

17.7 消息
   * 集群中各个节点通过发送和接受消息来进行通讯
      * meet、ping、pong、fail、publish
   * 消息头
      * 发送者自身的消息
      * 通过Gossip协议交换各自关于不同节点的状态信息

***Chapter 18. 发布与订阅***

18.1 频道的订阅与退订
   * 数据结构
   ```
   struct redisServer {
      dict *pubsub_channels; // channel_name ==> client_list
   };
   ```
   * subscribe
   ```
   def subscribe(* all_input_channels):
      for channel in all_input_channels:
         if channel not in server.pubsub_channels:
            server.pubsub_channels[channel] = []
         server.pubsub_channels[channel].append(client)
   ```
   * unscribe
   ```
   def unsubscribe(* all_input_channels):
      for channel in all_input_channels:
         server.pubsub_channels[channel].remove(client)
      if len(server.pubsub_chanels[chanel]) == 0:
         server.pubsub_channels.remove(channel)
   ```

18.2 模式的订阅与退订
   * 数据结构
   ```
   struct redisServer {
      list *pubsub_patterns;
   };
   typedef struct pubsubPattern {
      redisClient *client;
      robj *pattern;
   }
   ```
   * psubscribe 
   ```
   def psubscribe(* all_input_patterns):
      for pattern in all_input_patterns:
         pubsubPatter = create_new_pubsubPattern()
         pubsubPattern.client = client
         pubsubPattern.pattern = pattern
         server.pubsub_pattern.append(pubsubPattern)
   ```
   * punsubscribe
   ```
   def punsubscribe( *all_input_patterns):
      for pattern in all_input_patterns:
         for pubsubPattern in server.pubsub_pattersn:
            if client == pubsubPattern.client and 
               pattern == pubsubPattern.pattern
               server.pubsub_pattern.remove(pubsubPattern)
   ```

18.3 发送消息
   * 命令
      PUBLISH <channel> <message>
   * 将消息发送给频道订阅者
   ```
   def channel_publish(channel, message):
      if channel not in server.pubsub_channels:
         return
      for subscribe in server.pubsub_channels[channel]:
         send_message(subscribe, message)
   ```
   * 将消息发送给模式订阅者
   ```
   def pattern_publish(channel, message):
      for pubsubPattern in server.pubsub_patterns:
         if match(chanel, pubsubPattern.pattern):
            send_message(pubsubPattern.client, )
   ```
   ```
   def publish(channel, message):
      channel_publish(channel, message)
      pattern_publish(channel, message)
   ```

18.4 查看订阅信息
   * PUBSUB CHANNELS
   * PUBSUB NUMSUB
   * PUBSUB NUMPAT

***Chapter 19: 事务***

   redis通过Multi，exec，watch等命令来实现事务

19.1 事务的实现
   * 事务的撒个几段
      1. 事务开始
      1. 命令入队
      1. 事务执行
   * 事务开始
   ```
   def MULTI():
      client.falgs |= REDIS_MULTI
      replyOK()
   ```   
   * 命令入队：当客户端切换到事务状态之后
      * 如果客户端发送的命令为EXEC、DISCARD、WATCH、MULTI四个命令中的一个，那么服务器立即执行这个命令
      * 与此相反，如果客户端发送的命令是四个命令之外的命令，那么服务端并不立即执行，而是放入一个事务队列里面，然后向客户端返回QUEUED返回
      * 事务队列
      ```
      struct redisClient {
         multiState mstate;
      };
      struct multiState {
         multiCmd *commands;
         int count;
      };
      struct multiCmd {
         robj **argv;
         int aragc;
         redisCommand *cmd;
      };
      ```
   * 执行事务
   ```
   def EXEC():
      reply_queue = []
      for argv, argc, cmd in client.mstate.commands:
         reply = execute_command(cmd, argv, argc)
         reply_queue.append(reply)
      client.flags &= ~REDIS_MULTI

      client.mstate.count = 0
      release_transaction_queue(client.mstate.commands)

      send_reply_to_client(client, reply_queue)
   ```

19.2 WATCH 命令的实现
   * watch命令是一个乐观锁（optimistic locking）
   * 使用watch命令监视数据库键
      * 数据结构
      ```
      struct redisDb {
         dict *watched_keys;// map[string ==> list_of_clients]
      }
      ```
      * 监视机制的触发
      ```
      def touchWatchKey(db, key):
         if key in db.watched_keys:
            for client in db.watched_keys:
               client.flags |= REDIS_DIRTY_CAS
      ```
      * 判断事务是否安全
         * flags

19.3 事务的ACID性质
   * 原子性
      * 特别之处是，redis不支持事务回滚，即使运行命令过程中有错误还是会运行完所有的命令
   * 一致性
      * 入队错度：服务器会拒绝执行
      * 执行错误：出错也不会中断，还会继续执行剩下的操作
      * 服务器停机：持久化
   * 隔离性
      * redis使用担心啊城的方式来执行事务
   * 耐久性

***Chapter 20: Lua脚本***

20.1 创建并修改Lua环境
   * 创建一个基础的Lua环境， 之后的所有修改都是基于这个环境的
   * 载入多个函数库到Lua环境里面， 让lua脚本可以使用这些库函数进行操作
   * 创建全局表格redis，这个表格包含对redis进行操作的函数，比如lua脚本中执行redis命令的redis.call函数
   * 使用redis自制的随机函数来替换Lua中额随机函数
   * 创建排序辅助函数
   * 创建redis.pcall函数的错误报告辅助函数
   * 对lua环境中的全局环境进行保护， 防止运行lua脚本过程中， 将额外的全局变量添加到lua环境中

20.2 Lua环境协作组件
   * 伪客户端
      * lua环境 <===> 伪客户端 <===> 命令执行器
   * lua scripts字典
   ```
   struct redisServer {
      dict *lua_scripts;// map[check_sum(script) => script]
   };
   ```

20.3 EVAL命令的实现
   * 三个步骤
      1. 根据客户端给定的Lua脚本， 在lua环境中定义一个Lua函数
      1. 将客户端给定的标本保存到lua_scripts;
      1. 执行刚刚在lua环境定义的函数

20.4 EVALSHA命令的实现
   ```
   def EVALSHA(sha1):
      func_name = "f_" + sha1
      if function_exists_in_lua_env(func_name):
         execute_lua_function(func_name)
      else:
         send_script_error("SCRIPT NOT FOUND")
   ``` 

20.5 脚本管理命令的实现
   * SCRIPT FLUSH
   ```
   def SCRIPT_FLUSH() :
      dictRelease(sever.lua_scripts)
      server.lua_scripts = dictCreate(...)
      lua_close(server.lua)
      server.lua = init_lua_env()
   ```   
   * script exists 命令
      * for循环遍历
   * script load命令
   * script kill
      * 如果服务器设置了lua-time-limit 配置选项，那么在每次执行lua脚本之前，服务器都会在lua环境里面设置一个超时的处理钩子(hook).

20.6 脚本复制
   * 主从模式下，具有复制写的命令也会被复制到复制服务器
   * 复制EVAL精灵、script flush、script load命令
      * 主服务器向从服务器传播命令
   * 复制EVALSHA命令
      * 为了避免各个服务器上不一致，redis要求主服务器在传播evalsha命令的时候，必须确保evalsha命令要执行的脚本已经被所有的服务器载入过；如果不能确保，主服务器会将evalsha命令转换成一个等价eval命令， 然后通过传播eval命令来代替evalsha命令
      * 判断传播evalshsa命令是否安全: 用字典保存已经同步给所有从节点的脚本
      ```
      struct redisServer {
         dict *repl_scriptcache_dict; // map[script_hash ==> NULL]
      }
      ```
      * 清空repl_scriptcache_dict字典
         * 每当主服务器添加新的从服务器，主服务器会清空自己repl_scriptcache_dict字典，强制自己向所有的从服务器传播脚本
      * evalsha命令转换成eval命令的方法
      * 传播eevalsha命令的方法

***Chapter 21：排序***

21.1 sort <key>的实现
   * 排序方法：生成一个数组，然后排序（quick sort算法）
   ```
   typdef struct _redisSortObject {
      robj *obj; // 被排序键的值
      union {
          double score; // 排序数字值时使用
          robj *cmpobj; // 排序带有BY选项的字符串值时使用
      } u;
   } redisSortObject;
   ```      

21.2 ALPHA选项

21.3 ASC选项和DESC选项 

21.4 by选项的实现

21.5 带有ALPHA选项的BY选项的实现

21.6 LIMIT选项的实现

21.7 GET选项的实现

21.8 STORE选项的实现

21.9 多个选项的执行顺序


***Chapter 22：二进制位数组***

22.1 位数组表示
   * 使用SDS表示

22.2 GETBIT 命令的实现
   * getbit <bitarray> <offset>

22.3 setbit 命令的实现
   * 此处可能涉及位的扩展

22.4 bitcount命令的实现
   * 常见方法
      1. 遍历法：检查每个bit
      1. 查表发：byte ==> count
      1. variable-precision SWAR算法
   * redis的实现
      * 查表法 + variable-precision SWAR算法
         * >=128 调用四次 variable-precision SWAR算法
         * < 128 使用查表法

22.5 BITOP命令的实现


***Chapter 23：慢查询日志***
    
   * 该功能是用来记录执行时间超过给定长度的命令请求
      * slowlog-log-slower-than: 指定执行时间超过多少微妙
      * slowlog-max-len： 服务器最多保存多少条

23.1 慢查询记录的保存
   * 数据结构
   ```
   struct redisServer {
      //....
      long long slowlog_entry_id;
      // list of slowlogEntry, 添加到表头，从尾部删除
      list *slowlog; 
      //
      long long slowlog_log_slower_than;
      unsinged long slowlog_max_len;
   };

   typedef struct slowlogEntry {
      long long id;
      time_t time;
      long long duration;
      robj **argv;
      int argc;
   } slowlogEntry;
   ```

***Chapter 24：监视器***
   * MONITOR命令

24.1 成为监视器
   * 代码
   ```
   def MONITOR():
      client.flags |= REDIS_MONITOR
      server.monitors.appedn(client)
      send_reply("OK")
   ```

24.2 向监视器发送命令信息
   * 服务器在每次处理命令请求之前，都会调用replicationFeedMonitor函数，该函数将被处理的命令请求发送给各个监视器
   ```
   def replicationFeedMonitors(client, monitors, dbid, argv, argc):
      msg = create_message(client, dbid, argv, argc)
      for monitor in monitors:
         send_message(monitor, msg)
   ```   




















